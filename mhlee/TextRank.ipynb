{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"./data/정치.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-a02c3e3f642e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m13\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'content'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtitle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "n = 13\n",
    "content = df['content'][n]\n",
    "title = df['title'][n] \n",
    "\n",
    "import re\n",
    "def pre(content) :\n",
    "    content = content[68:]\n",
    "    src = re.search(r'(\\..{0,30}기자[ \\,])' ,content)\n",
    "    if src :\n",
    "        content = content[:src.span()[0]+1]\n",
    "    #print(len(content))\n",
    "    ad_re = re.compile('(\\[.{0,20}\\])|(\\(.{0,20}\\))|(▶.*)')\n",
    "    content = ad_re.sub('', content)\n",
    "    return content\n",
    "\n",
    "content = pre(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = '북미 정상회담 성과와 과제 북한 <조선중앙통신>은 김정은 국무위원장과 도널드 트럼프 미국 대통령이 2월28일 베트남 하노이 메트로폴 호텔에서 단독회담과 확대회담을 했다고 1일 보도했다. 평양/조선중앙통신 연합뉴스  합의 없이 끝난 하노이 2차 북-미 정상회담은 “한반도의 항구적이고 공고한 평화체제 구축”이라는 긴 여정의 새 출발점일 수밖에 없다. 김정은 국무위원장과 도널드 트럼프 대통령의 ‘하노이 담판’ 결과는 새 모색의 실마리이자 추동력이 될 ‘성과’와 함께 3차 정상회담을 성취하려면 반드시 풀어야 할 ‘과제’도 드러냈다.  성과① 확인된 ‘상황 관리’ 능력 관계 악화 막으려 상대 배려 후퇴 않는다는 ‘역진 방지’ 공감 “두 정상이 회담 이후 서로를 배려하며 상황 관리에 애를 쓰고 있다. 이번에 확인된 가장 큰 성과의 하나다.” “두 정상이 ‘판을 깰 생각이 없다’는 뜻을 분명히 하고 있다.” 고위 소식통은 3일 “북-미 정상이 ‘역진 방지’에 공감한다는 게 확인되고 있다”며 “후퇴만 하지 않는다면 다시 전진할 수 있다”고 기대 섞인 분석을 내놨다. 실제 김 위원장은 하노이 회담에서 “생산적인 대화들을 계속 이어나가기로 했다”는 메시지를 <노동신문>을 통해 내놨다. 트럼프 대통령도 회담 직후 기자회견에서 “김 위원장과 관계가 매우 돈독하다. 궁극적으로 서로 합의할 수 있을 것”이라고 강조했다. 성과② 드러난 ‘거래의 조건’ 비핵화·제재 완화 수위 확인 불확실성 제거로 새 회담 기반  “북한이 영변 핵시설을 통째로 포기할 생각이 있다는 사실이 처음으로 확인됐다. 영변이 폐기되면 나머지 비핵화 과정이 빨라질 수 있다. 가장 큰 성과다.” “불확실성이 제거되고 모든 쟁점이 분명해졌다. 3차 정상회담에서 더 높은 차원의 합의가 이뤄질 기반이 마련됐다.”(조성렬 전 국가안보전략연구원 선임연구위원) 이종석 전 장관은 “북쪽이 영변 핵시설 영구 폐기, 더구나 미국 전문가의 사찰·검증과 북-미 양국 기술자의 공동작업 폐기 방안을 제안한 사실이 매우 중요하다”며 “새로운 모색의 기반이 될 것”이라고 짚었다. 실제 리용호 외무상은 하노이 심야 회견에서 ①영변 핵시설의 영구 폐기 ②핵실험·장거리로켓발사 영구 중지 문서 약속을 주고, “2016~2017년 유엔 제재 결의 5건 중 민수경제·인민생활에 지장을 주는 항목 먼저 해제”를 받고 싶다는 뜻을 분명히 했다. 트럼프 대통령과 마이크 폼페이오 국무장관은 영변 핵시설 폐기를 넘어 “우리가 발견한 다른 것”과 “미사일, 탄두, 무기시스템”이 포함된 ‘신고 리스트’를 제출해야 ‘제재 해제’를 줄 수 있다고 밝혔다. 성과③ 보완된 ‘톱다운 방식’ 두 정상 ‘톱다운 단점’ 보완할 실무협상 힘 실린 건 성과 트럼프 대통령은 회담 직후 회견에서 “선언문이 준비돼 있었다”고 밝혔다. 김혁철 국무위원회 대미특별대표와 스티븐 비건 국무부 대북특별대표가 실무협상에서 ‘정상회담 합의문 초안’을 마련하는 데 성공했다는 뜻이다. “1차 회담에 비해 톱다운 방식의 단점이 적잖이 보완됐다”거나 “톱다운+실무협상 방식이 여전히 유효하다”는 진단이 나오는 배경이다.  과제①  여전한 신뢰 부족 미 ‘빅딜 아니면 노딜’ 전략 북 거부감 강해 걸림돌로 하노이 회담이 던진 가장 큰 화두는 비핵화 개념·방식을 둘러싼 북-미의 여전한 ‘신뢰 부족’을 어떻게 극복하느냐다. 미국 쪽은 북쪽의 ‘단계적 동시 행동 원칙’을 비핵화 의지 부족이라 읽는다. 북쪽은 이번에 드러난 미국 쪽의 “빅딜 아니면 노딜” 전략을 협상 의지 부족으로 여긴다. 골이 깊다. 미국 내 정책 혼선은 해법 찾기를 더 어렵게 한다. 비건 대표는 1월31일 스탠퍼드대 강연에서 “동시·병행” 추진 원칙을 밝혀 ‘핵신고’를 앞세우지 않을 뜻을 내비쳤다. 그런데 트럼프 대통령은 미국 의회·여론의 압력에 떠밀려 ‘빅딜 아니면 노딜’로 돌아섰고, 폼페이오 장관은 ‘핵신고’를 요구했다. 북-미 이견뿐만 아니라 미국 내부 혼선도 해소해야 할 과제다. 과제② 교착 장기화는 위험 미 대선 진입 땐 협상 어려워 올 안에 합의 못하면 장기화 “내년엔 미국 대선이 있어 올해가 아니면 합의가 어렵다.” 김준형 교수는 하노이 회담에서 양쪽의 ‘협상 카드’가 분명하게 드러난 게 “양날의 칼이 될 수 있다”고 짚었다. 불확실성 해소가 자칫 두 정상의 자존심 싸움으로 번지면 추동력이 급격히 소실될 위험이 있다는 것이다. 다수 전문가들이 “당분간 냉각기를 갖는 게 불가피하겠지만 교착 장기화는 위험하다”며 “협상이 조기 재개되도록 한국 정부가 최선을 다해야 한다”고 주문하는 까닭이다. 고위 소식통은 “트럼프 행정부의 정책 혼선이 가속화될 위험이 있다”며 “이제부터는 시간 싸움”이라고 강조했다.  과제③ 발목 잡힌 남북관계 남북 관계로 북미 동력 살리고 북·미·중과 능동적 외교 나서야 다수 전문가들은 “금강산관광이나 개성공단 재개 등의 기본적인 요구도 이번 회담 합의 무산으로 불투명해졌다”고 우려했다. 이관세 경남대 극동문제연구소장은 “비핵화 때까지 남북관계를 유보할 수 없다”며 “남북관계로 북-미 관계의 동력을 만들 수 있다”고 말했다. 이종석 전 장관은 정부가 “미국, 북한과 접촉하고 중국과 협조”하는 한편 “치열한 내부 토론”으로 창의적 방안을 마련해 적극적·능동적 외교에 나서야 한다고 주문했다.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from konlpy.tag import Mecab\n",
    "\n",
    "def tokenize(content, modelpath=\"../../model/\", morphs_file=\"morphs_dict\", comp_file=\"comps_dict\", category=\"정치\") :\n",
    "    def subtokenize(pos_list, dct) :\n",
    "        pos_str = \"[\" + \", \".join([str(t) for t in pos_list]) + \"]\"\n",
    "        for pattern in dct :\n",
    "            src = \", \".join([str(i) for i in pattern[1]])\n",
    "            tgt = str(pattern[0])\n",
    "            pos_str = pos_str.replace(src, tgt)\n",
    "\n",
    "        tokenized_text = eval(pos_str)\n",
    "        return tokenized_text\n",
    "    \n",
    "    mecab = Mecab()\n",
    "    tokenized_text = mecab.pos(content)\n",
    "        \n",
    "    morphs_dict = pickle.load(open('{}{}.pickle'.format(modelpath, morphs_file),\"rb\"))\n",
    "    tokenized_text = subtokenize(tokenized_text, morphs_dict[category])\n",
    "    \n",
    "    comp_dict = pickle.load(open('{}{}.pickle'.format(modelpath, comp_file),\"rb\"))\n",
    "    tokenized_text = subtokenize(tokenized_text, comp_dict[category])\n",
    "    \n",
    "    return tokenized_text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from konlpy.tag import Mecab\n",
    "import networkx as nx\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "class TextRank :\n",
    "    def __init__(self, text) :\n",
    "        self.tokens = self.pos_tagging(text)\n",
    "\n",
    "    def pos_tagging(self, content):\n",
    "        def group_by_pos(tokens, join_char='') :\n",
    "            return (join_char.join([t[0] for t in tokens]), 'NNP' if len(set([t[1] for t in tokens])) > 2 else tokens[-1][1] )\n",
    "\n",
    "        def gen_tokens(tokens, join_char='', group_by_pos_li = ['NNP', 'NNG', 'SN', 'SH', 'SL', 'NNBC'], stop_pos=[]) :\n",
    "            last_token = tokens[0]\n",
    "\n",
    "            ret = []\n",
    "            li = []\n",
    "            for t in tokens :\n",
    "                if t[1] in group_by_pos_li : li.append(t)\n",
    "                else :\n",
    "                    if len(li) > 0 : ret.append(group_by_pos(li, join_char))\n",
    "                    if t[1] not in stop_pos : ret.append(t)\n",
    "                    li=[]\n",
    "            if len(li) > 0 : ret.append(group_by_pos(li, join_char))\n",
    "\n",
    "            return ret\n",
    "\n",
    "        mecab = Mecab()\n",
    "        stop_pos = ['IC', 'JKS', 'JKC', 'JKG', 'JKO', 'JKB', 'JKV', 'JKQ', 'JC','JX'\n",
    "                    , 'XR', 'SF', 'SE', 'SSO', 'SSC', 'SC', 'SY', 'EC', 'EF', 'ETN', 'ETM', 'XSV', 'XSA', 'XSN', 'XPN']\n",
    "        ret = []\n",
    "        for s in sent_tokenize(content) :\n",
    "            #ret.append((s, sent_li))\n",
    "            sent_li= []\n",
    "            #sent_li.append([(w, gen_tokens(mecab.pos(w), stop_pos=stop_pos)) for w in s.split()])\n",
    "            sent_li.append([(w, gen_tokens(mecab.pos(w), stop_pos=stop_pos)) for w in s.split()])\n",
    "\n",
    "            \n",
    "            #for w in s.split() : sent_li.append((w, gen_tokens(mecab.pos(w))))\n",
    "            ret.append((s, sent_li))\n",
    "            #ret.append((s, [t for t in gen_tokens(sent_li, join_char= ' ') if t[1] not in stop_pos]))\n",
    "\n",
    "        return ret\n",
    "        \n",
    "    def keywords(self, n=10) :        \n",
    "        tokens = [t for s in self.tokens for w in s[1] for t in w]\n",
    "        nodes = [k for t in tokens for k in t[1] if (k[1][0] in ['N', 'V']) & (len(k[0])>1)]\n",
    "        tokens = [k for t in tokens for k in t[1]]\n",
    "        \n",
    "        def connect(nodes, tokens) :            \n",
    "            window_size = 5 # coocurrence를 판단하기 위한 window 사이즈 설정\n",
    "\n",
    "            edges = []\n",
    "            for window_start in range(0,(len(tokens)-window_size+1)):\n",
    "                window = tokens[window_start:window_start+window_size]            \n",
    "                #edges.append([(window[i], window[j]) for i in range(window_size) for j in range(window_size) if ( (i > j) & (window[i] in nodes) & (window[j] in nodes))])\n",
    "\n",
    "                for i in range(window_size) :\n",
    "                    for j in range(window_size) : \n",
    "                        if (i > j) & (window[i] in nodes) & (window[j] in nodes) :            \n",
    "                            edges.append((window[i], window[j]))\n",
    "            return edges\n",
    "\n",
    "        graph=nx.diamond_graph()\n",
    "        graph.clear() #처음 생성시 graph에 garbage node가 남아있어 삭제\n",
    "        graph.add_nodes_from(list(set(nodes))) #node 등록\n",
    "        graph.add_edges_from(connect(nodes, tokens)) #edge 연결\n",
    "        scores = nx.pagerank(graph) #pagerank 계산\n",
    "        rank = sorted(scores.items(), key=lambda x: x[1], reverse=True) #score 역순 정렬\n",
    "        return rank[:n]\n",
    "    \n",
    "    def print_keywords(self, n=10) :   \n",
    "        print(\"Keyword : \")\n",
    "        for k in self.keywords(n) :\n",
    "            print(\"{} - {}\".format(k[0][0], k[1]))\n",
    "    \n",
    "    def summarize(self, n=3) :\n",
    "        #자카드 유사도 계산\n",
    "        def jaccard_similarity(query, document):\n",
    "            intersection = set(query).intersection(set(document))\n",
    "            union = set(query).union(set(document))\n",
    "            return len(intersection)/len(union)\n",
    "\n",
    "        # 문장간 유사도 측정 (BoW를 활용 코사인 유사도 측정)\n",
    "        def sentence_similarity(sentence1, sentence2):\n",
    "            mecab = Mecab()\n",
    "            \n",
    "            sentence1 = mecab.morphs(sentence1[0])#[t[0] for s in sentence1[1][0] for t in s[1] if t[1][0] in ['N','V'] ] \n",
    "            sentence2 = mecab.morphs(sentence2[0])#.split()#[t[0] for s in sentence2[1][0] for t in s[1] if t[1][0] in ['N','V'] ]\n",
    "            #print(sentence1)\n",
    "            return jaccard_similarity(sentence1, sentence2)\n",
    "\n",
    "        def sentences(doc):\n",
    "            return [s[0].strip() for s in doc]\n",
    "\n",
    "        def connect(doc):\n",
    "            return [(start[0].strip(),end[0].strip() ,sentence_similarity(start, end)) \n",
    "                    for start in doc for end in doc if start is not end]\n",
    "        \n",
    "        graph=nx.diamond_graph()\n",
    "        graph.clear() #처음 생성시 graph에 garbage node가 남아있어 삭제\n",
    "        graph.add_nodes_from(sentences(self.tokens)) #node 등록\n",
    "        graph.add_weighted_edges_from(connect(self.tokens)) #edge 연결\n",
    "        scores = nx.pagerank(graph) #pagerank 계산\n",
    "        #print(scores)\n",
    "        rank = sorted(scores.items(), key=lambda x: x[1], reverse=True) #score 역순 정렬\n",
    "        return rank[:n]\n",
    "    \n",
    "    def print_summarize(self, n=3) :   \n",
    "        print(\"Summarize : \")\n",
    "        for s in self.summarize(n) :\n",
    "\n",
    "            print(\"{} - {}\".format(s[0], s[1]))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원문\n",
      " ‘북·미 판 깰 의도 없다’ 확인했지만…교착 장기화 막아야 \n",
      "북미 정상회담 성과와 과제 북한 <조선중앙통신>은 김정은 국무위원장과 도널드 트럼프 미국 대통령이 2월28일 베트남 하노이 메트로폴 호텔에서 단독회담과 확대회담을 했다고 1일 보도했다. 평양/조선중앙통신 연합뉴스  합의 없이 끝난 하노이 2차 북-미 정상회담은 “한반도의 항구적이고 공고한 평화체제 구축”이라는 긴 여정의 새 출발점일 수밖에 없다. 김정은 국무위원장과 도널드 트럼프 대통령의 ‘하노이 담판’ 결과는 새 모색의 실마리이자 추동력이 될 ‘성과’와 함께 3차 정상회담을 성취하려면 반드시 풀어야 할 ‘과제’도 드러냈다.  성과① 확인된 ‘상황 관리’ 능력 관계 악화 막으려 상대 배려 후퇴 않는다는 ‘역진 방지’ 공감 “두 정상이 회담 이후 서로를 배려하며 상황 관리에 애를 쓰고 있다. 이번에 확인된 가장 큰 성과의 하나다.” “두 정상이 ‘판을 깰 생각이 없다’는 뜻을 분명히 하고 있다.” 고위 소식통은 3일 “북-미 정상이 ‘역진 방지’에 공감한다는 게 확인되고 있다”며 “후퇴만 하지 않는다면 다시 전진할 수 있다”고 기대 섞인 분석을 내놨다. 실제 김 위원장은 하노이 회담에서 “생산적인 대화들을 계속 이어나가기로 했다”는 메시지를 <노동신문>을 통해 내놨다. 트럼프 대통령도 회담 직후 기자회견에서 “김 위원장과 관계가 매우 돈독하다. 궁극적으로 서로 합의할 수 있을 것”이라고 강조했다. 성과② 드러난 ‘거래의 조건’ 비핵화·\n",
      "\n",
      "---- krayon ----\n",
      "Keyword : \n",
      "회담 - 0.01808343233691793\n",
      "미국 - 0.015118195432661727\n",
      "트럼프 - 0.011476840513489921\n",
      "하노이 - 0.010921497119051597\n",
      "비핵화 - 0.010897973452043906\n",
      "\n",
      "Summarize : \n",
      "이번에 확인된 가장 큰 성과의 하나다.” “두 정상이 ‘판을 깰 생각이 없다’는 뜻을 분명히 하고 있다.” 고위 소식통은 3일 “북-미 정상이 ‘역진 방지’에 공감한다는 게 확인되고 있다”며 “후퇴만 하지 않는다면 다시 전진할 수 있다”고 기대 섞인 분석을 내놨다. - 0.03784092942062531\n",
      "성과③ 보완된 ‘톱다운 방식’ 두 정상 ‘톱다운 단점’ 보완할 실무협상 힘 실린 건 성과 트럼프 대통령은 회담 직후 회견에서 “선언문이 준비돼 있었다”고 밝혔다. - 0.03763918269950607\n",
      "과제② 교착 장기화는 위험 미 대선 진입 땐 협상 어려워 올 안에 합의 못하면 장기화 “내년엔 미국 대선이 있어 올해가 아니면 합의가 어렵다.” 김준형 교수는 하노이 회담에서 양쪽의 ‘협상 카드’가 분명하게 드러난 게 “양날의 칼이 될 수 있다”고 짚었다. - 0.036652698717126675\n",
      "\n",
      "---- gensim ----\n",
      "['트럼프', '하노이', '비핵화', '장관은', '폼페이오', '드러난', '합의가', '있다는', '정상회담', '불확실성', '밝혔다', '강조했다', '실무협상', '회담에서', '접촉하고', '압력에', '장기화', '불확실성이', '당분간', '금강산관광이나', '이번에', '방안을']\n",
      "북미 정상회담 성과와 과제 북한 <조선중앙통신>은 김정은 국무위원장과 도널드 트럼프 미국 대통령이 2월28일 베트남 하노이 메트로폴 호텔에서 단독회담과 확대회담을 했다고 1일 보도했다.\n",
      "이번에 확인된 가장 큰 성과의 하나다.” “두 정상이 ‘판을 깰 생각이 없다’는 뜻을 분명히 하고 있다.” 고위 소식통은 3일 “북-미 정상이 ‘역진 방지’에 공감한다는 게 확인되고 있다”며 “후퇴만 하지 않는다면 다시 전진할 수 있다”고 기대 섞인 분석을 내놨다.\n",
      "3차 정상회담에서 더 높은 차원의 합의가 이뤄질 기반이 마련됐다.”(조성렬 전 국가안보전략연구원 선임연구위원) 이종석 전 장관은 “북쪽이 영변 핵시설 영구 폐기, 더구나 미국 전문가의 사찰·검증과 북-미 양국 기술자의 공동작업 폐기 방안을 제안한 사실이 매우 중요하다”며 “새로운 모색의 기반이 될 것”이라고 짚었다.\n",
      "과제①  여전한 신뢰 부족 미 ‘빅딜 아니면 노딜’ 전략 북 거부감 강해 걸림돌로 하노이 회담이 던진 가장 큰 화두는 비핵화 개념·방식을 둘러싼 북-미의 여전한 ‘신뢰 부족’을 어떻게 극복하느냐다.\n",
      "그런데 트럼프 대통령은 미국 의회·여론의 압력에 떠밀려 ‘빅딜 아니면 노딜’로 돌아섰고, 폼페이오 장관은 ‘핵신고’를 요구했다.\n",
      "과제② 교착 장기화는 위험 미 대선 진입 땐 협상 어려워 올 안에 합의 못하면 장기화 “내년엔 미국 대선이 있어 올해가 아니면 합의가 어렵다.” 김준형 교수는 하노이 회담에서 양쪽의 ‘협상 카드’가 분명하게 드러난 게 “양날의 칼이 될 수 있다”고 짚었다.\n"
     ]
    }
   ],
   "source": [
    "print(\"원문\")\n",
    "print(title)\n",
    "print(content[:700])\n",
    "print()\n",
    "print(\"---- krayon ----\")\n",
    "tr = TextRank(pre(content))\n",
    "tr.print_keywords(5)\n",
    "print()\n",
    "tr.print_summarize(3)\n",
    "\n",
    "print(\"\\n---- gensim ----\")\n",
    "from gensim.summarization import keywords\n",
    "from gensim.summarization.summarizer import summarize\n",
    "print(keywords(content, ratio = 0.1).split('\\n'))\n",
    "print(summarize(content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def daily_issue(date) : \n",
    "    for content in sub_df[sub_df.date==date]['content'][:100] :\n",
    "        content = pre(content)\n",
    "        tr = TextRank(content)\n",
    "        tr.print_keywords(5)\n",
    "        tr.print_summarize()\n",
    "        print()\n",
    "        \n",
    "sub_df = df[df.category2==\"정치일반\"]\n",
    "daily_issue('2020-03-03')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        for rank in textrank(processed_text, 10) :\n",
    "            if rank[0] not in d.keys() : \n",
    "                d[rank[0]] = rank[1]   \n",
    "            else :\n",
    "                d[rank[0]] = d[rank[0]] + rank[1]\n",
    "\n",
    "    n = 10\n",
    "    cnt = 0\n",
    "    print(date)\n",
    "    li = []\n",
    "    for item in {k: v for k, v in sorted(d.items(), key=lambda item: item[1], reverse=True)} :\n",
    "        li.append(item)\n",
    "        cnt = cnt + 1\n",
    "        if n == cnt :\n",
    "            break\n",
    "    print(li)\n",
    "    return li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "a = []\n",
    "\n",
    "for d in pd.date_range('2020-03-03','2020-03-17') :\n",
    "    dstr = d.strftime('%Y-%m-%d')\n",
    "    bb = daily_issue(d.strftime('%Y-%m-%d'))\n",
    "    #print(bb)\n",
    "    a.append((dstr, bb))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "dct = defaultdict()\n",
    "\n",
    "for d in a :\n",
    "    for i in d[1] :\n",
    "        if i not in dct.keys() :\n",
    "            dct[i] = 1\n",
    "        else :\n",
    "            dct[i] = dct[i] + 1\n",
    "\n",
    "print(\"공통이슈\")            \n",
    "for k in dct.keys() :\n",
    "    if dct[k] > 5:\n",
    "        print(k)\n",
    "        \n",
    "print(\"\\n날짜별이슈\")                        \n",
    "for d in a :\n",
    "    print(d[0])\n",
    "    for i in d[1] :\n",
    "        if dct[i] < 5 :\n",
    "            print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('인간', 'NNG'),\n",
       " ('이', 'JKS'),\n",
       " ('컴퓨터', 'NNG'),\n",
       " ('와', 'JC'),\n",
       " ('대화', 'NNG'),\n",
       " ('하', 'XSV'),\n",
       " ('고', 'EC'),\n",
       " ('있', 'VX'),\n",
       " ('다는', 'ETM'),\n",
       " ('것', 'NNB'),\n",
       " ('을', 'JKO'),\n",
       " ('깨닫', 'VV'),\n",
       " ('지', 'EC'),\n",
       " ('못하', 'VX'),\n",
       " ('고', 'EC'),\n",
       " ('인간', 'NNG'),\n",
       " ('과', 'JC'),\n",
       " ('대화', 'NNG'),\n",
       " ('를', 'JKO'),\n",
       " ('계속', 'NNG'),\n",
       " ('할', 'XSV+ETM'),\n",
       " ('수', 'NNB'),\n",
       " ('있', 'VV'),\n",
       " ('다면', 'EC'),\n",
       " ('컴퓨터', 'NNG'),\n",
       " ('는', 'JX'),\n",
       " ('지능', 'NNG'),\n",
       " ('적', 'XSN'),\n",
       " ('인', 'VCP+ETM'),\n",
       " ('것', 'NNB'),\n",
       " ('으로', 'JKB'),\n",
       " ('간주', 'NNG'),\n",
       " ('될', 'XSV+ETM'),\n",
       " ('수', 'NNB'),\n",
       " ('있', 'VV'),\n",
       " ('습니다', 'EF'),\n",
       " ('.', 'SF')]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from konlpy.tag import Mecab\n",
    "mecab = Mecab()\n",
    "\n",
    "txt = \"인간이 컴퓨터와 대화하고 있다는 것을 깨닫지 못하고 인간과 대화를 계속할 수 있다면 컴퓨터는 지능적인 것으로 간주될 수 있습니다.\"\n",
    "\n",
    "[t for t in mecab.pos(txt)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyword : \n",
      "데이터 - 0.03973351287685013\n",
      "활용 - 0.016701290714366292\n",
      "센터 - 0.016275674362980122\n",
      "플랫폼 - 0.015730600824899948\n",
      "통해 - 0.012409792934616403\n",
      "\n",
      "Summarize : \n",
      "이런 맥락 속에서 빅데이터센터는 공공과 민간이 협업해 활용도 높은 양질의 데이터를 생산·구축하고, 플랫폼은 이를 수집·분석·유통하는 역할을 담당한다. - 0.05674588725570076\n",
      "센터와 플랫폼 간 연계체계에는 민간 클라우드를 기반으로 활용하고, 센터에 축적된 데이터도 계속 외부와 개방·공유하며 최신·연속성을 확보한다는 계획이다. - 0.05348664505845348\n",
      "이를 통해 데이터 생태계를 혁신하고 기업의 경쟁력을 제고하는 역할을 수행한다. - 0.051884720925367604\n"
     ]
    }
   ],
   "source": [
    "content = '과기정통부, 22일 유영민 장관 등 참석해 기념행사 2021년까지 1516억원 투입, 5100여종 데이터 구축 민간 클라우드 통한 외부연계체계도..\"개방성 강화\" [이데일리 이재운 기자] 국가 차원의 빅데이터 활용 시대가 열린다. 새로운 산업 창출과 기존 산업의 변화에 이르는 ‘혁신성장’을 위한 센터가 문을 연다. 10개 분야에 걸쳐 ‘데이터 경제’의 발전을 위한 정부의 청사진을 현실로 구현하는데 앞장선다는 계획이다. 22일 과학기술정보통신부는 서울 중구 대한상공회의소에서 데이터 생태계 조성과 혁신 성장의 기반 마련을 위한 ‘빅데이터 플랫폼 및 센터’ 출범식 행사를 개최했다. 유영민 과기정통부 장관을 비롯해 노웅래 국회 과학기술정보방송통신위원회 위원장 등 300여명이 참가했다. ◇10개 분야 100개 센터..3년간 1516억원 투입 이미지: 픽사베이 빅데이터는 데이터 활용을 통해 혁신성장을 이루자는 문재인 정부의 경제 성장 핵심 요소중 하나다. 문재인 대통령이 직접 올 들어 데이터 활용과 이에 따른 정보보호(보안)에 대한 중요성을 강조하기도 했다. 이런 맥락 속에서 빅데이터센터는 공공과 민간이 협업해 활용도 높은 양질의 데이터를 생산·구축하고, 플랫폼은 이를 수집·분석·유통하는 역할을 담당한다. 과기정통부는 분야별 플랫폼 10개소와 이와 연계된 기관별 센터 100개소를 구축하는데 3년간 총 1516억원을 투입할 계획이며, 올해 우선 640억원 규모의 사업을 추진하고 있다. 대상 분야는 △금융(BC카드) △환경(한국수자원공사) △문화(한국문화정보원) △교통(한국교통연구원) △헬스케어(국립암센터) △유통·소비(매일방송) △통신(KT) △중소기업(더존비즈온) △지역경제(경기도청) △산림(한국임업진흥원) 등으로 현재 1차 공모를 통해 72개 빅데이터 센터를 선정했고, 다음달 8일까지 2차 공모를 통해 28개를 추가 선정해 총 100개를 지원, 운영할 계획이다. 이를 통해 데이터 생태계를 혁신하고 기업의 경쟁력을 제고하는 역할을 수행한다. 주요 활용 전략·사례를 보면 빅데이터 활용을 통해 ‘신(新) 시장’을 창출하는 방안을 담고 있다. 금융 플랫폼의 경우 소상공인 신용평가 고도화 등을 통해 금융 취약 계층 대상 중금리 대출이자를 2%p 절감해 연간 1조원의 신규대출을 창출할 전망이다. 유통·소비와 중소기업 플랫폼은 소상공인이나 중소기업의 폐업률 감소를, 문화 플랫폼은 문화·예술 관람률과 생활체육 참여율을 높이는 방안을 모색한다. 의료비 절감(헬스케어)과 기업의 매출 향상을 통한 산업 육성(통신·산림) 등도 눈길을 끈다. 과기정통부 제공 ◇2021년까지 5100여종 데이터 구축..AI 알고리즘 제공도 센터는 우선 분야별 데이터 부족 문제를 해소하기 위해 올해 말까지 시장 수요가 높은 1400여종 신규 데이터를 생산ㆍ구축하고, 사업이 완료되는 2021년까지 총 5100여종 양질의 풍부한 데이터를 생산·구축해 시장에 공급할 계획이다. 특히 공공과 민간 사이 데이터 파일형식 등이 달라 호환이 제대로 이뤄지지 못한 문제를 해소하기 위해 개방형 표준을 적용하고, 품질관리기준도 마련해 운영한다. 기업들이 실제 활용 가능한 최신 데이터를 확보하는데도 수개월이 소요된다는 문제점을 개선하기 위한 방안도 추진한다. 센터와 플랫폼 간 연계체계에는 민간 클라우드를 기반으로 활용하고, 센터에 축적된 데이터도 계속 외부와 개방·공유하며 최신·연속성을 확보한다는 계획이다. 100개 센터에서 수집된 데이터를 융합·분석한 뒤 맞춤형 데이터 제작 등 양질의 데이터로 재생산하고, 기업들이 필요로 하는 데이터를 원하는 형태로 즉시 활용할 수 있도록 제공할 계획이다. 다양한 분석 도구는 물론 인공지능(AI) 학습 알고리즘도 제공해 이용자가 보다 사용하기 편리한 환경을 제공한다. 이밖에 필요한 데이터를 쉽게 등록하고 검색할 수 있도록 기준을 마련하고, 데이터 보유와 관리에 대한 체계(거버넌스)를 논의하는 ‘데이터 얼라이언스’를 구성해 보다 안전하게 이용하는 방안도 마련했다. 유영민 과기정통부 장관은 “오늘 출범식은 대한민국이 데이터 강국으로 가기 위한 초석을 놓은 자리”라며 “세계 주요국들보다 데이터 경제로 나아가는 발걸음이 다소 늦었지만, 빅데이터 플랫폼과 센터를 지렛대로 우리나라의 낙후된 데이터 생태계를 혁신하고 기업의 경쟁력을 한 단계 제고할 수 있도록 정책적 역량을 집중하겠다”고 밝혔다. 이재운 (jwlee@edaily.co.kr) 네이버 홈에서 ‘이데일리’ 뉴스 [구독하기▶] 꿀잼가득 [영상보기▶] , 청춘뉘우스~ [스냅타임▶] ＜ⓒ종합 경제정보 미디어 이데일리 - 무단전재 & 재배포 금지＞'\n",
    "tr = TextRank(pre(content))\n",
    "tr.print_keywords(5)\n",
    "print()\n",
    "tr.print_summarize(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
