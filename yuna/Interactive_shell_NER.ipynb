{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "dl_py3",
      "language": "python",
      "name": "dl_py3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "source": [],
        "metadata": {
          "collapsed": false
        }
      }
    },
    "colab": {
      "name": "Interactive_shell_NER.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "leQR7nPHSLdt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "outputId": "f27841be-9a82-4fc4-80ce-cb84cb1a877c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XOvjO43SSSA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e2127100-38d6-4c22-c3af-13b167db1f7a"
      },
      "source": [
        "cd /content/drive/My Drive/fininsight/Kobert_ner/pytorch-bert-crf-ner/"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/fininsight/Kobert_ner/pytorch-bert-crf-ner\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eaggbjY4SZUC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 155
        },
        "outputId": "aeb307fe-a458-4826-a5a4-95cffcf86b86"
      },
      "source": [
        "ls"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'=0.1.6'    \u001b[0m\u001b[01;34mdata_utils\u001b[0m/                   LICENSE\n",
            "'=0.4.0'    download.sh                   metric.py\n",
            "'=0.6.0'    evaluate.py                   \u001b[01;34mmodel\u001b[0m/\n",
            "'=1.5.0'    \u001b[01;34mexperiments\u001b[0m/                  \u001b[01;34mptr_lm_model\u001b[0m/\n",
            " app.py     inference.py                  README.md\n",
            " \u001b[01;34massets\u001b[0m/    Interactive_shell_NER.ipynb   \u001b[01;34mtemplates\u001b[0m/\n",
            " \u001b[01;34mbertviz\u001b[0m/   \u001b[01;34mkobert\u001b[0m/                       train_bert_crf.py\n",
            " \u001b[01;34mdata_in\u001b[0m/   \u001b[01;34mlegacy\u001b[0m/                       Visualization_BERT_NER.ipynb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SdLHovhhSD5m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! pip install torch torchvision\n",
        "! pip install pytorch_pretrained_bert>=0.4.0\n",
        "! pip install mxnet>=1.5.0\n",
        "! pip install gluonnlp #>=0.6.0\n",
        "! pip install sentencepiece>=0.1.6\n",
        "! pip install git+https://github.com/kmkurn/pytorch-crf#egg=pytorch_crf\n",
        "! pip install transformers\n",
        "! pip install tb-nightly\n",
        "! pip install future"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SY-EZUKjSrdd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! pip install konlpy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-27T09:44:13.362955Z",
          "start_time": "2019-11-27T09:44:07.902764Z"
        },
        "id": "gphcT9snR8hi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import json\n",
        "import pickle\n",
        "import torch\n",
        "from gluonnlp.data import SentencepieceTokenizer\n",
        "from model.net import KobertCRF\n",
        "from data_utils.utils import Config\n",
        "from data_utils.vocab_tokenizer import Tokenizer\n",
        "from data_utils.pad_sequence import keras_pad_fn\n",
        "from pathlib import Path"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-27T09:44:13.406972Z",
          "start_time": "2019-11-27T09:44:13.370406Z"
        },
        "id": "NsownfCpR8hs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DecoderFromNamedEntitySequence():\n",
        "    def __init__(self, tokenizer, index_to_ner):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.index_to_ner = index_to_ner\n",
        "\n",
        "    def __call__(self, list_of_input_ids, list_of_pred_ids):\n",
        "        input_token = self.tokenizer.decode_token_ids(list_of_input_ids)[0]\n",
        "        pred_ner_tag = [self.index_to_ner[pred_id] for pred_id in list_of_pred_ids[0]]\n",
        "\n",
        "        # ----------------------------- parsing list_of_ner_word ----------------------------- #\n",
        "        list_of_ner_word = []\n",
        "        entity_word, entity_tag, prev_entity_tag = \"\", \"\", \"\"\n",
        "        for i, pred_ner_tag_str in enumerate(pred_ner_tag):\n",
        "            if \"B-\" in pred_ner_tag_str:\n",
        "                entity_tag = pred_ner_tag_str[-3:]\n",
        "\n",
        "                if prev_entity_tag != entity_tag and prev_entity_tag != \"\":\n",
        "                    list_of_ner_word.append({\"word\": entity_word.replace(\"▁\", \" \"), \"tag\": prev_entity_tag, \"prob\": None})\n",
        "\n",
        "                entity_word = input_token[i]\n",
        "                prev_entity_tag = entity_tag\n",
        "            elif \"I-\"+entity_tag in pred_ner_tag_str:\n",
        "                entity_word += input_token[i]\n",
        "            else:\n",
        "                if entity_word != \"\" and entity_tag != \"\":\n",
        "                    list_of_ner_word.append({\"word\":entity_word.replace(\"▁\", \" \"), \"tag\":entity_tag, \"prob\":None})\n",
        "                entity_word, entity_tag, prev_entity_tag = \"\", \"\", \"\"\n",
        "\n",
        "\n",
        "        # ----------------------------- parsing decoding_ner_sentence ----------------------------- #\n",
        "        decoding_ner_sentence = \"\"\n",
        "        is_prev_entity = False\n",
        "        prev_entity_tag = \"\"\n",
        "        is_there_B_before_I = False\n",
        "\n",
        "        for i, (token_str, pred_ner_tag_str) in enumerate(zip(input_token, pred_ner_tag)):\n",
        "            if i == 0 or i == len(pred_ner_tag)-1: # remove [CLS], [SEP]\n",
        "                continue\n",
        "            token_str = token_str.replace('▁', ' ')  # '▁' 토큰을 띄어쓰기로 교체\n",
        "\n",
        "            if 'B-' in pred_ner_tag_str:\n",
        "                if is_prev_entity is True:\n",
        "                    decoding_ner_sentence += ':' + prev_entity_tag+ '>'\n",
        "\n",
        "                if token_str[0] == ' ':\n",
        "                    token_str = list(token_str)\n",
        "                    token_str[0] = ' <'\n",
        "                    token_str = ''.join(token_str)\n",
        "                    decoding_ner_sentence += token_str\n",
        "                else:\n",
        "                    decoding_ner_sentence += '<' + token_str\n",
        "                is_prev_entity = True\n",
        "                prev_entity_tag = pred_ner_tag_str[-3:] # 첫번째 예측을 기준으로 하겠음\n",
        "                is_there_B_before_I = True\n",
        "\n",
        "            elif 'I-' in pred_ner_tag_str:\n",
        "                decoding_ner_sentence += token_str\n",
        "\n",
        "                if is_there_B_before_I is True: # I가 나오기전에 B가 있어야하도록 체크\n",
        "                    is_prev_entity = True\n",
        "            else:\n",
        "                if is_prev_entity is True:\n",
        "                    decoding_ner_sentence += ':' + prev_entity_tag+ '>' + token_str\n",
        "                    is_prev_entity = False\n",
        "                    is_there_B_before_I = False\n",
        "                else:\n",
        "                    decoding_ner_sentence += token_str\n",
        "\n",
        "        return list_of_ner_word, decoding_ner_sentence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HC7qnWKUUjpV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! pip install pytorch-transformers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCVhT4WoUPxP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "60b84ef7-02f5-4764-9cf0-6c41d044a725"
      },
      "source": [
        "! python train_bert_crf.py"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/konlpy/tag/_okt.py:16: UserWarning: \"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.\n",
            "  warn('\"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.')\n",
            "using cached model\n",
            "[██████████████████████████████████████████████████]\n",
            "using cached model\n",
            "len(token_to_idx):  8002\n",
            "num of files:  1425\n",
            "num of files:  2\n",
            "using cached model\n",
            "using cached model\n",
            "num of train: 23032, num of val: 931\n",
            "Epoch:   0% 0/15 [00:00<?, ?it/s]\n",
            "Iteration:   0% 0/90 [00:00<?, ?it/s]\u001b[Aepoch : 1, global_step : 1, tr_loss: 24537.520, tr_acc: 5.78%\n",
            "\n",
            "Iteration:   1% 1/90 [01:15<1:51:40, 75.28s/it]\u001b[Aepoch : 1, global_step : 2, tr_loss: 22135.842, tr_acc: 63.53%\n",
            "\n",
            "Iteration:   2% 2/90 [02:25<1:48:03, 73.68s/it]\u001b[Aepoch : 1, global_step : 3, tr_loss: 20525.904, tr_acc: 66.71%\n",
            "\n",
            "Iteration:   3% 3/90 [03:34<1:44:51, 72.32s/it]\u001b[Aepoch : 1, global_step : 4, tr_loss: 19261.059, tr_acc: 67.00%\n",
            "\n",
            "Iteration:   4% 4/90 [04:43<1:42:15, 71.34s/it]\u001b[Aepoch : 1, global_step : 5, tr_loss: 18320.475, tr_acc: 65.62%\n",
            "\n",
            "Iteration:   6% 5/90 [05:52<1:40:06, 70.67s/it]\u001b[Aepoch : 1, global_step : 6, tr_loss: 17495.364, tr_acc: 67.08%\n",
            "\n",
            "Iteration:   7% 6/90 [07:01<1:38:20, 70.24s/it]\u001b[Aepoch : 1, global_step : 7, tr_loss: 16821.565, tr_acc: 67.53%\n",
            "\n",
            "Iteration:   8% 7/90 [08:10<1:36:42, 69.90s/it]\u001b[Aepoch : 1, global_step : 8, tr_loss: 16232.533, tr_acc: 68.47%\n",
            "\n",
            "Iteration:   9% 8/90 [09:19<1:35:11, 69.65s/it]\u001b[Aepoch : 1, global_step : 9, tr_loss: 15760.669, tr_acc: 67.25%\n",
            "\n",
            "Iteration:  10% 9/90 [10:29<1:33:51, 69.52s/it]\u001b[Aepoch : 1, global_step : 10, tr_loss: 15355.461, tr_acc: 67.48%\n",
            "\n",
            "Iteration:  11% 10/90 [11:38<1:32:32, 69.40s/it]\u001b[Aepoch : 1, global_step : 11, tr_loss: 15042.182, tr_acc: 65.38%\n",
            "\n",
            "Iteration:  12% 11/90 [12:47<1:31:18, 69.35s/it]\u001b[Aepoch : 1, global_step : 12, tr_loss: 14719.395, tr_acc: 67.28%\n",
            "\n",
            "Iteration:  13% 12/90 [13:56<1:30:07, 69.33s/it]\u001b[Aepoch : 1, global_step : 13, tr_loss: 14424.438, tr_acc: 68.40%\n",
            "\n",
            "Iteration:  14% 13/90 [15:05<1:28:53, 69.27s/it]\u001b[Aepoch : 1, global_step : 14, tr_loss: 14197.014, tr_acc: 65.80%\n",
            "\n",
            "Iteration:  16% 14/90 [16:15<1:27:42, 69.25s/it]\u001b[Aepoch : 1, global_step : 15, tr_loss: 13941.128, tr_acc: 69.11%\n",
            "\n",
            "Iteration:  17% 15/90 [17:24<1:26:30, 69.20s/it]\u001b[Aepoch : 1, global_step : 16, tr_loss: 13706.159, tr_acc: 67.84%\n",
            "\n",
            "Iteration:  18% 16/90 [18:33<1:25:18, 69.17s/it]\u001b[Aepoch : 1, global_step : 17, tr_loss: 13507.147, tr_acc: 67.10%\n",
            "\n",
            "Iteration:  19% 17/90 [19:42<1:24:08, 69.16s/it]\u001b[Aepoch : 1, global_step : 18, tr_loss: 13352.371, tr_acc: 64.23%\n",
            "\n",
            "Iteration:  20% 18/90 [20:51<1:23:00, 69.18s/it]\u001b[Aepoch : 1, global_step : 19, tr_loss: 13197.018, tr_acc: 67.18%\n",
            "\n",
            "Iteration:  21% 19/90 [22:00<1:21:48, 69.13s/it]\u001b[Aepoch : 1, global_step : 20, tr_loss: 13062.399, tr_acc: 66.09%\n",
            "\n",
            "Iteration:  22% 20/90 [23:09<1:20:38, 69.13s/it]\u001b[Aepoch : 1, global_step : 21, tr_loss: 12901.724, tr_acc: 67.83%\n",
            "\n",
            "Iteration:  23% 21/90 [24:18<1:19:27, 69.09s/it]\u001b[Aepoch : 1, global_step : 22, tr_loss: 12790.135, tr_acc: 64.94%\n",
            "\n",
            "Iteration:  24% 22/90 [25:27<1:18:17, 69.08s/it]\u001b[Aepoch : 1, global_step : 23, tr_loss: 12644.617, tr_acc: 68.28%\n",
            "\n",
            "Iteration:  26% 23/90 [26:37<1:17:09, 69.10s/it]\u001b[Aepoch : 1, global_step : 24, tr_loss: 12496.846, tr_acc: 69.88%\n",
            "\n",
            "Iteration:  27% 24/90 [27:46<1:16:00, 69.10s/it]\u001b[Aepoch : 1, global_step : 25, tr_loss: 12392.498, tr_acc: 65.49%\n",
            "\n",
            "Iteration:  28% 25/90 [28:55<1:14:52, 69.11s/it]\u001b[Aepoch : 1, global_step : 26, tr_loss: 12282.277, tr_acc: 66.61%\n",
            "\n",
            "Iteration:  29% 26/90 [30:04<1:13:42, 69.10s/it]\u001b[Aepoch : 1, global_step : 27, tr_loss: 12175.793, tr_acc: 66.64%\n",
            "\n",
            "Iteration:  30% 27/90 [31:13<1:12:33, 69.10s/it]\u001b[Aepoch : 1, global_step : 28, tr_loss: 12077.248, tr_acc: 68.00%\n",
            "\n",
            "Iteration:  31% 28/90 [32:22<1:11:21, 69.06s/it]\u001b[Aepoch : 1, global_step : 29, tr_loss: 11971.150, tr_acc: 70.12%\n",
            "\n",
            "Iteration:  32% 29/90 [33:31<1:10:11, 69.05s/it]\u001b[Aepoch : 1, global_step : 30, tr_loss: 11890.796, tr_acc: 67.20%\n",
            "\n",
            "Iteration:  33% 30/90 [34:40<1:09:03, 69.05s/it]\u001b[Aepoch : 1, global_step : 31, tr_loss: 11798.965, tr_acc: 70.18%\n",
            "\n",
            "Iteration:  34% 31/90 [35:49<1:07:57, 69.10s/it]\u001b[Aepoch : 1, global_step : 32, tr_loss: 11718.309, tr_acc: 67.71%\n",
            "\n",
            "Iteration:  36% 32/90 [36:58<1:06:50, 69.15s/it]\u001b[Aepoch : 1, global_step : 33, tr_loss: 11630.726, tr_acc: 68.70%\n",
            "\n",
            "Iteration:  37% 33/90 [38:08<1:05:44, 69.20s/it]\u001b[Aepoch : 1, global_step : 34, tr_loss: 11527.528, tr_acc: 71.01%\n",
            "\n",
            "Iteration:  38% 34/90 [39:17<1:04:34, 69.19s/it]\u001b[Aepoch : 1, global_step : 35, tr_loss: 11441.345, tr_acc: 69.47%\n",
            "\n",
            "Iteration:  39% 35/90 [40:26<1:03:26, 69.22s/it]\u001b[Aepoch : 1, global_step : 36, tr_loss: 11352.905, tr_acc: 70.34%\n",
            "\n",
            "Iteration:  40% 36/90 [41:35<1:02:17, 69.21s/it]\u001b[Aepoch : 1, global_step : 37, tr_loss: 11257.522, tr_acc: 71.72%\n",
            "\n",
            "Iteration:  41% 37/90 [42:44<1:01:04, 69.14s/it]\u001b[Aepoch : 1, global_step : 38, tr_loss: 11170.946, tr_acc: 69.98%\n",
            "\n",
            "Iteration:  42% 38/90 [43:53<59:53, 69.11s/it]  \u001b[Aepoch : 1, global_step : 39, tr_loss: 11089.666, tr_acc: 71.13%\n",
            "\n",
            "Iteration:  43% 39/90 [45:02<58:41, 69.06s/it]\u001b[Aepoch : 1, global_step : 40, tr_loss: 11000.440, tr_acc: 74.64%\n",
            "\n",
            "Iteration:  44% 40/90 [46:11<57:31, 69.02s/it]\u001b[Aepoch : 1, global_step : 41, tr_loss: 10917.694, tr_acc: 75.50%\n",
            "\n",
            "Iteration:  46% 41/90 [47:20<56:21, 69.02s/it]\u001b[Aepoch : 1, global_step : 42, tr_loss: 10830.529, tr_acc: 76.20%\n",
            "\n",
            "Iteration:  47% 42/90 [48:29<55:14, 69.05s/it]\u001b[Aepoch : 1, global_step : 43, tr_loss: 10743.597, tr_acc: 75.32%\n",
            "\n",
            "Iteration:  48% 43/90 [49:39<54:05, 69.06s/it]\u001b[Aepoch : 1, global_step : 44, tr_loss: 10664.662, tr_acc: 75.02%\n",
            "\n",
            "Iteration:  49% 44/90 [50:48<52:57, 69.08s/it]\u001b[Aepoch : 1, global_step : 45, tr_loss: 10586.274, tr_acc: 74.26%\n",
            "\n",
            "Iteration:  50% 45/90 [51:57<51:49, 69.11s/it]\u001b[Aepoch : 1, global_step : 46, tr_loss: 10495.982, tr_acc: 77.31%\n",
            "\n",
            "Iteration:  51% 46/90 [53:06<50:41, 69.12s/it]\u001b[Aepoch : 1, global_step : 47, tr_loss: 10413.960, tr_acc: 76.22%\n",
            "\n",
            "Iteration:  52% 47/90 [54:15<49:30, 69.07s/it]\u001b[Aepoch : 1, global_step : 48, tr_loss: 10333.399, tr_acc: 76.04%\n",
            "\n",
            "Iteration:  53% 48/90 [55:24<48:20, 69.05s/it]\u001b[Aepoch : 1, global_step : 49, tr_loss: 10262.988, tr_acc: 75.99%\n",
            "\n",
            "Iteration:  54% 49/90 [56:33<47:10, 69.03s/it]\u001b[Aepoch : 1, global_step : 50, tr_loss: 10174.535, tr_acc: 80.43%\n",
            "\n",
            "\n",
            "Evaluating:   0% 0/4 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  25% 1/4 [00:24<01:13, 24.47s/it]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  50% 2/4 [00:47<00:48, 24.13s/it]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  75% 3/4 [01:11<00:23, 23.86s/it]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating: 100% 4/4 [01:26<00:00, 21.20s/it]\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:224: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
            "eval acc: 0.809846043586731, loss: 5684.96630859375, global steps: 50\n",
            "Average loss: 10174.535283203126 at global step: 50\n",
            "\n",
            "Iteration:  56% 50/90 [59:08<1:03:15, 94.89s/it]\u001b[Aepoch : 1, global_step : 51, tr_loss: 10103.075, tr_acc: 77.22%\n",
            "\n",
            "Iteration:  57% 51/90 [1:00:18<56:48, 87.41s/it]\u001b[Aepoch : 1, global_step : 52, tr_loss: 10025.904, tr_acc: 78.15%\n",
            "\n",
            "Iteration:  58% 52/90 [1:01:27<51:52, 81.92s/it]\u001b[Aepoch : 1, global_step : 53, tr_loss: 9951.643, tr_acc: 79.19%\n",
            "\n",
            "Iteration:  59% 53/90 [1:02:36<48:09, 78.09s/it]\u001b[Aepoch : 1, global_step : 54, tr_loss: 9880.797, tr_acc: 77.92%\n",
            "\n",
            "Iteration:  60% 54/90 [1:03:46<45:14, 75.41s/it]\u001b[Aepoch : 1, global_step : 55, tr_loss: 9803.487, tr_acc: 79.78%\n",
            "\n",
            "Iteration:  61% 55/90 [1:04:55<42:52, 73.50s/it]\u001b[Aepoch : 1, global_step : 56, tr_loss: 9734.135, tr_acc: 78.84%\n",
            "\n",
            "Iteration:  62% 56/90 [1:06:04<40:53, 72.15s/it]\u001b[Aepoch : 1, global_step : 57, tr_loss: 9654.869, tr_acc: 81.98%\n",
            "\n",
            "Iteration:  63% 57/90 [1:07:13<39:10, 71.24s/it]\u001b[Aepoch : 1, global_step : 58, tr_loss: 9586.012, tr_acc: 80.67%\n",
            "\n",
            "Iteration:  64% 58/90 [1:08:22<37:39, 70.60s/it]\u001b[Aepoch : 1, global_step : 59, tr_loss: 9520.336, tr_acc: 79.32%\n",
            "\n",
            "Iteration:  66% 59/90 [1:09:31<36:15, 70.17s/it]\u001b[Aepoch : 1, global_step : 60, tr_loss: 9451.366, tr_acc: 80.41%\n",
            "\n",
            "Iteration:  67% 60/90 [1:10:40<34:54, 69.83s/it]\u001b[Aepoch : 1, global_step : 61, tr_loss: 9378.182, tr_acc: 82.01%\n",
            "\n",
            "Iteration:  68% 61/90 [1:11:49<33:38, 69.60s/it]\u001b[Aepoch : 1, global_step : 62, tr_loss: 9308.495, tr_acc: 81.69%\n",
            "\n",
            "Iteration:  69% 62/90 [1:12:58<32:25, 69.47s/it]\u001b[Aepoch : 1, global_step : 63, tr_loss: 9244.074, tr_acc: 81.11%\n",
            "\n",
            "Iteration:  70% 63/90 [1:14:07<31:13, 69.38s/it]\u001b[Aepoch : 1, global_step : 64, tr_loss: 9175.595, tr_acc: 83.16%\n",
            "\n",
            "Iteration:  71% 64/90 [1:15:17<30:03, 69.35s/it]\u001b[Aepoch : 1, global_step : 65, tr_loss: 9109.183, tr_acc: 82.57%\n",
            "\n",
            "Iteration:  72% 65/90 [1:16:26<28:52, 69.30s/it]\u001b[Aepoch : 1, global_step : 66, tr_loss: 9052.588, tr_acc: 80.39%\n",
            "\n",
            "Iteration:  73% 66/90 [1:17:35<27:41, 69.24s/it]\u001b[Aepoch : 1, global_step : 67, tr_loss: 8989.948, tr_acc: 82.88%\n",
            "\n",
            "Iteration:  74% 67/90 [1:18:44<26:31, 69.21s/it]\u001b[Aepoch : 1, global_step : 68, tr_loss: 8934.048, tr_acc: 80.70%\n",
            "\n",
            "Iteration:  76% 68/90 [1:19:53<25:21, 69.14s/it]\u001b[Aepoch : 1, global_step : 69, tr_loss: 8872.689, tr_acc: 82.80%\n",
            "\n",
            "Iteration:  77% 69/90 [1:21:02<24:11, 69.11s/it]\u001b[Aepoch : 1, global_step : 70, tr_loss: 8811.170, tr_acc: 84.06%\n",
            "\n",
            "Iteration:  78% 70/90 [1:22:11<23:02, 69.13s/it]\u001b[Aepoch : 1, global_step : 71, tr_loss: 8749.101, tr_acc: 84.11%\n",
            "\n",
            "Iteration:  79% 71/90 [1:23:20<21:53, 69.13s/it]\u001b[Aepoch : 1, global_step : 72, tr_loss: 8686.894, tr_acc: 85.29%\n",
            "\n",
            "Iteration:  80% 72/90 [1:24:30<20:44, 69.12s/it]\u001b[Aepoch : 1, global_step : 73, tr_loss: 8628.566, tr_acc: 84.75%\n",
            "\n",
            "Iteration:  81% 73/90 [1:25:38<19:33, 69.06s/it]\u001b[Aepoch : 1, global_step : 74, tr_loss: 8571.786, tr_acc: 85.06%\n",
            "\n",
            "Iteration:  82% 74/90 [1:26:47<18:24, 69.05s/it]\u001b[Aepoch : 1, global_step : 75, tr_loss: 8517.313, tr_acc: 84.38%\n",
            "\n",
            "Iteration:  83% 75/90 [1:27:57<17:16, 69.07s/it]\u001b[Aepoch : 1, global_step : 76, tr_loss: 8460.897, tr_acc: 85.61%\n",
            "\n",
            "Iteration:  84% 76/90 [1:29:06<16:07, 69.10s/it]\u001b[Aepoch : 1, global_step : 77, tr_loss: 8406.413, tr_acc: 84.63%\n",
            "\n",
            "Iteration:  86% 77/90 [1:30:15<14:58, 69.09s/it]\u001b[Aepoch : 1, global_step : 78, tr_loss: 8349.715, tr_acc: 86.40%\n",
            "\n",
            "Iteration:  87% 78/90 [1:31:24<13:48, 69.07s/it]\u001b[Aepoch : 1, global_step : 79, tr_loss: 8297.194, tr_acc: 85.70%\n",
            "\n",
            "Iteration:  88% 79/90 [1:32:33<12:39, 69.07s/it]\u001b[Aepoch : 1, global_step : 80, tr_loss: 8243.520, tr_acc: 85.91%\n",
            "\n",
            "Iteration:  89% 80/90 [1:33:42<11:31, 69.11s/it]\u001b[Aepoch : 1, global_step : 81, tr_loss: 8188.213, tr_acc: 87.05%\n",
            "\n",
            "Iteration:  90% 81/90 [1:34:51<10:22, 69.11s/it]\u001b[Aepoch : 1, global_step : 82, tr_loss: 8138.373, tr_acc: 85.92%\n",
            "\n",
            "Iteration:  91% 82/90 [1:36:00<09:12, 69.08s/it]\u001b[Aepoch : 1, global_step : 83, tr_loss: 8090.741, tr_acc: 85.27%\n",
            "\n",
            "Iteration:  92% 83/90 [1:37:09<08:03, 69.00s/it]\u001b[Aepoch : 1, global_step : 84, tr_loss: 8042.968, tr_acc: 87.00%\n",
            "\n",
            "Iteration:  93% 84/90 [1:38:18<06:53, 69.00s/it]\u001b[Aepoch : 1, global_step : 85, tr_loss: 7992.652, tr_acc: 87.99%\n",
            "\n",
            "Iteration:  94% 85/90 [1:39:27<05:44, 68.97s/it]\u001b[Aepoch : 1, global_step : 86, tr_loss: 7942.508, tr_acc: 87.77%\n",
            "\n",
            "Iteration:  96% 86/90 [1:40:36<04:35, 68.95s/it]\u001b[Aepoch : 1, global_step : 87, tr_loss: 7893.674, tr_acc: 88.13%\n",
            "\n",
            "Iteration:  97% 87/90 [1:41:45<03:26, 68.89s/it]\u001b[Aepoch : 1, global_step : 88, tr_loss: 7846.295, tr_acc: 88.30%\n",
            "\n",
            "Iteration:  98% 88/90 [1:42:53<02:17, 68.87s/it]\u001b[Aepoch : 1, global_step : 89, tr_loss: 7799.663, tr_acc: 88.41%\n",
            "\n",
            "Iteration:  99% 89/90 [1:44:02<01:08, 68.91s/it]\u001b[Aepoch : 1, global_step : 90, tr_loss: 7750.521, tr_acc: 89.58%\n",
            "\n",
            "Iteration: 100% 90/90 [1:45:09<00:00, 68.35s/it]\u001b[A\n",
            "Epoch:   7% 1/15 [1:45:10<24:32:21, 6310.08s/it]\n",
            "Iteration:   0% 0/90 [00:00<?, ?it/s]\u001b[Aepoch : 2, global_step : 91, tr_loss: 7702.200, tr_acc: 89.40%\n",
            "\n",
            "Iteration:   1% 1/90 [01:17<1:54:39, 77.30s/it]\u001b[Aepoch : 2, global_step : 92, tr_loss: 7658.056, tr_acc: 88.08%\n",
            "\n",
            "Iteration:   2% 2/90 [02:26<1:49:45, 74.84s/it]\u001b[Aepoch : 2, global_step : 93, tr_loss: 7612.499, tr_acc: 88.68%\n",
            "\n",
            "Iteration:   3% 3/90 [03:35<1:46:02, 73.13s/it]\u001b[Aepoch : 2, global_step : 94, tr_loss: 7564.822, tr_acc: 90.54%\n",
            "\n",
            "Iteration:   4% 4/90 [04:44<1:43:07, 71.95s/it]\u001b[Aepoch : 2, global_step : 95, tr_loss: 7520.033, tr_acc: 89.59%\n",
            "\n",
            "Iteration:   6% 5/90 [05:53<1:40:42, 71.09s/it]\u001b[Aepoch : 2, global_step : 96, tr_loss: 7474.235, tr_acc: 90.57%\n",
            "\n",
            "Iteration:   7% 6/90 [07:02<1:38:41, 70.49s/it]\u001b[Aepoch : 2, global_step : 97, tr_loss: 7427.569, tr_acc: 90.61%\n",
            "\n",
            "Iteration:   8% 7/90 [08:12<1:36:57, 70.09s/it]\u001b[Aepoch : 2, global_step : 98, tr_loss: 7382.969, tr_acc: 90.28%\n",
            "\n",
            "Iteration:   9% 8/90 [09:21<1:35:27, 69.85s/it]\u001b[Aepoch : 2, global_step : 99, tr_loss: 7339.822, tr_acc: 90.15%\n",
            "\n",
            "Iteration:  10% 9/90 [10:30<1:34:01, 69.65s/it]\u001b[Aepoch : 2, global_step : 100, tr_loss: 7296.151, tr_acc: 90.30%\n",
            "\n",
            "\n",
            "Evaluating:   0% 0/4 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  25% 1/4 [00:24<01:14, 24.68s/it]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  50% 2/4 [00:47<00:48, 24.27s/it]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  75% 3/4 [01:11<00:23, 23.99s/it]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating: 100% 4/4 [01:26<00:00, 21.28s/it]\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[Aeval acc: 0.9248120188713074, loss: 2640.614990234375, global steps: 100\n",
            "Average loss: 4417.766435546875 at global step: 100\n",
            "\n",
            "Iteration:  11% 10/90 [13:06<2:07:18, 95.48s/it]\u001b[Aepoch : 2, global_step : 101, tr_loss: 7254.296, tr_acc: 90.13%\n",
            "\n",
            "Iteration:  12% 11/90 [14:16<1:55:40, 87.85s/it]\u001b[Aepoch : 2, global_step : 102, tr_loss: 7213.154, tr_acc: 90.45%\n",
            "\n",
            "Iteration:  13% 12/90 [15:25<1:46:56, 82.26s/it]\u001b[Aepoch : 2, global_step : 103, tr_loss: 7173.868, tr_acc: 90.03%\n",
            "\n",
            "Iteration:  14% 13/90 [16:34<1:40:28, 78.29s/it]\u001b[Aepoch : 2, global_step : 104, tr_loss: 7134.990, tr_acc: 89.02%\n",
            "\n",
            "Iteration:  16% 14/90 [17:43<1:35:38, 75.51s/it]\u001b[Aepoch : 2, global_step : 105, tr_loss: 7097.502, tr_acc: 89.21%\n",
            "\n",
            "Iteration:  17% 15/90 [18:52<1:31:57, 73.57s/it]\u001b[Aepoch : 2, global_step : 106, tr_loss: 7059.481, tr_acc: 89.83%\n",
            "\n",
            "Iteration:  18% 16/90 [20:01<1:29:08, 72.28s/it]\u001b[Aepoch : 2, global_step : 107, tr_loss: 7021.927, tr_acc: 89.65%\n",
            "\n",
            "Iteration:  19% 17/90 [21:11<1:26:47, 71.33s/it]\u001b[Aepoch : 2, global_step : 108, tr_loss: 6982.671, tr_acc: 90.97%\n",
            "\n",
            "Iteration:  20% 18/90 [22:20<1:24:47, 70.65s/it]\u001b[Aepoch : 2, global_step : 109, tr_loss: 6943.415, tr_acc: 91.57%\n",
            "\n",
            "Iteration:  21% 19/90 [23:29<1:23:04, 70.21s/it]\u001b[Aepoch : 2, global_step : 110, tr_loss: 6906.768, tr_acc: 90.59%\n",
            "\n",
            "Iteration:  22% 20/90 [24:38<1:21:34, 69.92s/it]\u001b[Aepoch : 2, global_step : 111, tr_loss: 6872.543, tr_acc: 89.38%\n",
            "\n",
            "Iteration:  23% 21/90 [25:47<1:20:08, 69.69s/it]\u001b[Aepoch : 2, global_step : 112, tr_loss: 6833.713, tr_acc: 91.71%\n",
            "\n",
            "Iteration:  24% 22/90 [26:56<1:18:47, 69.52s/it]\u001b[Aepoch : 2, global_step : 113, tr_loss: 6797.976, tr_acc: 91.10%\n",
            "\n",
            "Iteration:  26% 23/90 [28:05<1:17:28, 69.38s/it]\u001b[Aepoch : 2, global_step : 114, tr_loss: 6762.036, tr_acc: 90.95%\n",
            "\n",
            "Iteration:  27% 24/90 [29:14<1:16:13, 69.29s/it]\u001b[Aepoch : 2, global_step : 115, tr_loss: 6728.207, tr_acc: 90.22%\n",
            "\n",
            "Iteration:  28% 25/90 [30:24<1:15:03, 69.29s/it]\u001b[Aepoch : 2, global_step : 116, tr_loss: 6695.100, tr_acc: 90.40%\n",
            "\n",
            "Iteration:  29% 26/90 [31:33<1:13:49, 69.21s/it]\u001b[Aepoch : 2, global_step : 117, tr_loss: 6662.504, tr_acc: 90.21%\n",
            "\n",
            "Iteration:  30% 27/90 [32:42<1:12:36, 69.14s/it]\u001b[Aepoch : 2, global_step : 118, tr_loss: 6629.983, tr_acc: 90.95%\n",
            "\n",
            "Iteration:  31% 28/90 [33:51<1:11:23, 69.09s/it]\u001b[Aepoch : 2, global_step : 119, tr_loss: 6596.741, tr_acc: 91.46%\n",
            "\n",
            "Iteration:  32% 29/90 [35:00<1:10:19, 69.17s/it]\u001b[Aepoch : 2, global_step : 120, tr_loss: 6563.511, tr_acc: 91.22%\n",
            "\n",
            "Iteration:  33% 30/90 [36:09<1:09:08, 69.15s/it]\u001b[Aepoch : 2, global_step : 121, tr_loss: 6531.292, tr_acc: 91.25%\n",
            "\n",
            "Iteration:  34% 31/90 [37:18<1:07:59, 69.14s/it]\u001b[Aepoch : 2, global_step : 122, tr_loss: 6499.988, tr_acc: 90.53%\n",
            "\n",
            "Iteration:  36% 32/90 [38:27<1:06:50, 69.15s/it]\u001b[Aepoch : 2, global_step : 123, tr_loss: 6471.214, tr_acc: 90.11%\n",
            "\n",
            "Iteration:  37% 33/90 [39:37<1:05:44, 69.20s/it]\u001b[Aepoch : 2, global_step : 124, tr_loss: 6440.508, tr_acc: 91.15%\n",
            "\n",
            "Iteration:  38% 34/90 [40:46<1:04:40, 69.29s/it]\u001b[Aepoch : 2, global_step : 125, tr_loss: 6408.314, tr_acc: 91.81%\n",
            "\n",
            "Iteration:  39% 35/90 [41:56<1:03:31, 69.30s/it]\u001b[Aepoch : 2, global_step : 126, tr_loss: 6375.402, tr_acc: 92.34%\n",
            "\n",
            "Iteration:  40% 36/90 [43:05<1:02:23, 69.32s/it]\u001b[Aepoch : 2, global_step : 127, tr_loss: 6345.671, tr_acc: 91.04%\n",
            "\n",
            "Iteration:  41% 37/90 [44:14<1:01:12, 69.29s/it]\u001b[Aepoch : 2, global_step : 128, tr_loss: 6315.632, tr_acc: 91.84%\n",
            "\n",
            "Iteration:  42% 38/90 [45:24<1:00:09, 69.42s/it]\u001b[Aepoch : 2, global_step : 129, tr_loss: 6286.109, tr_acc: 91.72%\n",
            "\n",
            "Iteration:  43% 39/90 [46:33<58:56, 69.35s/it]  \u001b[Aepoch : 2, global_step : 130, tr_loss: 6256.637, tr_acc: 91.29%\n",
            "\n",
            "Iteration:  44% 40/90 [47:42<57:45, 69.31s/it]\u001b[Aepoch : 2, global_step : 131, tr_loss: 6227.929, tr_acc: 92.20%\n",
            "\n",
            "Iteration:  46% 41/90 [48:51<56:33, 69.25s/it]\u001b[Aepoch : 2, global_step : 132, tr_loss: 6199.243, tr_acc: 91.64%\n",
            "\n",
            "Iteration:  47% 42/90 [50:01<55:22, 69.22s/it]\u001b[Aepoch : 2, global_step : 133, tr_loss: 6169.829, tr_acc: 92.59%\n",
            "\n",
            "Iteration:  48% 43/90 [51:10<54:15, 69.27s/it]\u001b[Aepoch : 2, global_step : 134, tr_loss: 6141.202, tr_acc: 92.86%\n",
            "\n",
            "Iteration:  49% 44/90 [52:19<53:03, 69.21s/it]\u001b[Aepoch : 2, global_step : 135, tr_loss: 6113.757, tr_acc: 91.95%\n",
            "\n",
            "Iteration:  50% 45/90 [53:28<51:54, 69.21s/it]\u001b[Aepoch : 2, global_step : 136, tr_loss: 6087.165, tr_acc: 91.75%\n",
            "\n",
            "Iteration:  51% 46/90 [54:37<50:44, 69.20s/it]\u001b[Aepoch : 2, global_step : 137, tr_loss: 6061.002, tr_acc: 91.75%\n",
            "\n",
            "Iteration:  52% 47/90 [55:47<49:37, 69.25s/it]\u001b[Aepoch : 2, global_step : 138, tr_loss: 6035.063, tr_acc: 91.48%\n",
            "\n",
            "Iteration:  53% 48/90 [56:56<48:26, 69.21s/it]\u001b[Aepoch : 2, global_step : 139, tr_loss: 6008.656, tr_acc: 91.98%\n",
            "\n",
            "Iteration:  54% 49/90 [58:05<47:17, 69.22s/it]\u001b[Aepoch : 2, global_step : 140, tr_loss: 5982.778, tr_acc: 91.87%\n",
            "\n",
            "Iteration:  56% 50/90 [59:14<46:07, 69.20s/it]\u001b[Aepoch : 2, global_step : 141, tr_loss: 5956.499, tr_acc: 92.11%\n",
            "\n",
            "Iteration:  57% 51/90 [1:00:23<44:57, 69.16s/it]\u001b[Aepoch : 2, global_step : 142, tr_loss: 5930.871, tr_acc: 92.24%\n",
            "\n",
            "Iteration:  58% 52/90 [1:01:33<43:50, 69.22s/it]\u001b[Aepoch : 2, global_step : 143, tr_loss: 5906.806, tr_acc: 91.67%\n",
            "\n",
            "Iteration:  59% 53/90 [1:02:42<42:41, 69.22s/it]\u001b[Aepoch : 2, global_step : 144, tr_loss: 5882.265, tr_acc: 92.10%\n",
            "\n",
            "Iteration:  60% 54/90 [1:03:51<41:31, 69.20s/it]\u001b[Aepoch : 2, global_step : 145, tr_loss: 5856.278, tr_acc: 92.60%\n",
            "\n",
            "Iteration:  61% 55/90 [1:05:00<40:21, 69.19s/it]\u001b[Aepoch : 2, global_step : 146, tr_loss: 5831.367, tr_acc: 92.32%\n",
            "\n",
            "Iteration:  62% 56/90 [1:06:10<39:18, 69.36s/it]\u001b[Aepoch : 2, global_step : 147, tr_loss: 5808.715, tr_acc: 90.59%\n",
            "\n",
            "Iteration:  63% 57/90 [1:07:19<38:07, 69.32s/it]\u001b[Aepoch : 2, global_step : 148, tr_loss: 5785.037, tr_acc: 92.09%\n",
            "\n",
            "Iteration:  64% 58/90 [1:08:28<36:55, 69.25s/it]\u001b[Aepoch : 2, global_step : 149, tr_loss: 5760.984, tr_acc: 92.90%\n",
            "\n",
            "Iteration:  66% 59/90 [1:09:38<35:48, 69.30s/it]\u001b[Aepoch : 2, global_step : 150, tr_loss: 5736.050, tr_acc: 93.20%\n",
            "\n",
            "\n",
            "Evaluating:   0% 0/4 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  25% 1/4 [00:24<01:14, 24.84s/it]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  50% 2/4 [00:48<00:48, 24.35s/it]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  75% 3/4 [01:11<00:23, 24.00s/it]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating: 100% 4/4 [01:26<00:00, 21.26s/it]\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[Aeval acc: 0.9402792453765869, loss: 1863.9794921875, global steps: 150\n",
            "Average loss: 2615.849189453125 at global step: 150\n",
            "\n",
            "Iteration:  67% 60/90 [1:12:14<47:37, 95.27s/it]\u001b[Aepoch : 2, global_step : 151, tr_loss: 5712.672, tr_acc: 92.78%\n",
            "\n",
            "Iteration:  68% 61/90 [1:13:24<42:24, 87.73s/it]\u001b[Aepoch : 2, global_step : 152, tr_loss: 5688.565, tr_acc: 93.24%\n",
            "\n",
            "Iteration:  69% 62/90 [1:14:33<38:20, 82.15s/it]\u001b[Aepoch : 2, global_step : 153, tr_loss: 5664.763, tr_acc: 93.04%\n",
            "\n",
            "Iteration:  70% 63/90 [1:15:43<35:19, 78.49s/it]\u001b[Aepoch : 2, global_step : 154, tr_loss: 5639.917, tr_acc: 94.01%\n",
            "\n",
            "Iteration:  71% 64/90 [1:16:52<32:49, 75.76s/it]\u001b[Aepoch : 2, global_step : 155, tr_loss: 5617.267, tr_acc: 92.98%\n",
            "\n",
            "Iteration:  72% 65/90 [1:18:01<30:43, 73.73s/it]\u001b[Aepoch : 2, global_step : 156, tr_loss: 5593.152, tr_acc: 94.04%\n",
            "\n",
            "Iteration:  73% 66/90 [1:19:10<28:56, 72.34s/it]\u001b[Aepoch : 2, global_step : 157, tr_loss: 5570.483, tr_acc: 92.87%\n",
            "\n",
            "Iteration:  74% 67/90 [1:20:19<27:20, 71.33s/it]\u001b[A"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-27T09:44:13.441346Z",
          "start_time": "2019-11-27T09:44:13.414934Z"
        },
        "id": "SStkthkBR8hv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def main(x):\n",
        "    model_dir = Path('./experiments/base_model_with_crf')\n",
        "    # /content/drive/My Drive/fininsight/Kobert_ner/pytorch-bert-crf-ner/experiments\n",
        "    model_config = Config(json_path=model_dir / 'config.json') \n",
        "    \n",
        "\n",
        "    # load vocab & tokenizer \n",
        "    tok_path = \"./ptr_lm_model/tokenizer_78b3253a26.model\" \n",
        "    ptr_tokenizer = SentencepieceTokenizer(tok_path)\n",
        "\n",
        "    with open(model_dir / \"vocab.pkl\", 'rb') as f:\n",
        "        vocab = pickle.load(f)\n",
        "    tokenizer = Tokenizer(vocab=vocab, split_fn=ptr_tokenizer, pad_fn=keras_pad_fn, maxlen=model_config.maxlen)\n",
        "\n",
        "    # load ner_to_index.json\n",
        "    with open(model_dir / \"ner_to_index.json\", 'rb') as f:\n",
        "        ner_to_index = json.load(f)\n",
        "        index_to_ner = {v: k for k, v in ner_to_index.items()}\n",
        "\n",
        "    # model\n",
        "    model = KobertCRF(config=model_config, num_classes=len(ner_to_index), vocab=vocab)\n",
        "\n",
        "    # load\n",
        "    model_dict = model.state_dict()\n",
        "    checkpoint = torch.load(\"./experiments/base_model_with_crf/best-epoch-16-step-1500-acc-0.993.bin\", map_location=torch.device('cpu'))\n",
        "    # checkpoint = torch.load(\"./experiments/base_model_with_crf_val/best-epoch-12-step-1000-acc-0.960.bin\", map_location=torch.device('cpu'))\n",
        "    convert_keys = {}\n",
        "    for k, v in checkpoint['model_state_dict'].items():\n",
        "        new_key_name = k.replace(\"module.\", '')\n",
        "        if new_key_name not in model_dict:\n",
        "            print(\"{} is not int model_dict\".format(new_key_name))\n",
        "            continue\n",
        "        convert_keys[new_key_name] = v\n",
        "\n",
        "    model.load_state_dict(convert_keys)\n",
        "    model.eval()\n",
        "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "    model.to(device)\n",
        "    decoder_from_res = DecoderFromNamedEntitySequence(tokenizer=tokenizer, index_to_ner=index_to_ner)\n",
        "\n",
        "    ner_text = []\n",
        "    for text in x:\n",
        "        input_text = text\n",
        "        list_of_input_ids = tokenizer.list_of_string_to_list_of_cls_sep_token_ids([input_text])\n",
        "        x_input = torch.tensor(list_of_input_ids).long()\n",
        "        list_of_pred_ids = model(x_input)\n",
        "\n",
        "        list_of_ner_word, decoding_ner_sentence = decoder_from_res(list_of_input_ids=list_of_input_ids, list_of_pred_ids=list_of_pred_ids)\n",
        "        ner_text.append(decoding_ner_sentence)\n",
        "\n",
        "    return ner_text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vEGnKBcg6DnF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "\n",
        "def pre_fx(text):\n",
        "      # 이메일 등장하면, 그 뒷문장 모두 삭제 \n",
        "      text = re.sub(\"[a-zA-Z0-9]+\\@[a-zA-Z0-9]+\\.[a-z]{1,3}.[a-z]{1,3}.+\",'',text).strip()\n",
        "      text = re.sub('\\(.+?연합뉴스\\)','',text).strip() # (서울=연합뉴스)\n",
        "      text = re.sub('\\(.+?연합인포맥스\\)','',text).strip()\n",
        "      text = re.sub('\\(.+?이데일리\\)','',text).strip()\n",
        "      text = re.sub('\\(.+?조선일보\\)','',text).strip()\n",
        "      text = re.sub('\\(.+?뉴시스\\)',' ',text).strip()\n",
        "      text = re.sub('\\(.+?뉴스1\\)','',text).strip()\n",
        "      text = re.sub('\\(.+?SBS\\)','',text).strip()\n",
        "      text = re.sub('\\(.+?오마이뉴스\\)','',text).strip()\n",
        "      text = re.sub('\\(.+?중앙일보\\)','',text).strip()\n",
        "      text = re.sub('\\(.+?매일경제\\)','',text).strip()\n",
        "      text = re.sub('\\(.+?문화일보\\)','',text).strip()\n",
        "      text = re.sub('\\(.+?세계일보\\)','',text).strip()\n",
        "      text = re.sub('\\(.+?머니투데이\\)','',text).strip()\n",
        "      text = re.sub('\\(.+?서울경제\\)','',text).strip()\n",
        "      text = re.sub('\\(.+?데일리안\\)','',text).strip()\n",
        "      text = re.sub('\\(.+?KBS\\)','',text).strip()\n",
        "      text = re.sub('\\(.+?MBN\\)','',text).strip()\n",
        "      text = re.sub('\\(.+?YTN\\)','',text).strip()\n",
        "      text = re.sub('\\(.+?프레시안\\)','',text).strip()\n",
        "      text = re.sub('\\(.+?디지털타임즈\\)','',text).strip()\n",
        "      text = re.sub('\\(.+?국민일보(과거)\\)','',text).strip()\n",
        "      text = re.sub('\\(.+?국민일보\\)','',text).strip()\n",
        "      text = re.sub('\\(.+?헤드럴경제\\)','',text).strip()\n",
        "      text = re.sub('\\(.+?한국일보\\)','',text).strip()\n",
        "      text = re.sub('\\(.+?아이뉴스24\\)','',text).strip()\n",
        "      text = re.sub('\\(.+?노컷뉴스\\)','',text).strip()\n",
        "      text = re.sub('\\(.+?연합뉴스TV\\)','',text).strip()\n",
        "      text = re.sub('\\(.+?서울일보\\)','',text).strip()\n",
        "      text = re.sub('\\(.+?동아일보\\)','',text).strip()\n",
        "      text = re.sub('\\(.+?한국경제\\)','',text).strip()\n",
        "      text = re.sub('\\(.+?미디어오늘(과거)\\)','',text).strip()\n",
        "      text = re.sub('\\(.+?미디어오늘\\)','',text).strip()\n",
        "      text = re.sub('\\(.+?조세일보\\)','',text).strip()\n",
        "      text = re.sub('\\(.+?파이낸셜뉴스\\)','',text).strip()\n",
        "      text = re.sub('\\(.+?경향신문\\)','',text).strip()\n",
        "      text = re.sub('\\(.+?채널A\\)','',text).strip()\n",
        "      text = re.sub('\\(.+?머니S\\)','',text).strip()\n",
        "      text = re.sub('\\(.+?TVCHOSUN\\)','',text).strip()\n",
        "      text = re.sub('\\(.+?한겨례\\)','',text).strip()\n",
        "      text = re.sub('\\(.+?전자신문\\)','',text).strip()\n",
        "      text = re.sub('\\(.+?SBSCNBC\\)','',text).strip()\n",
        "      text = re.sub('\\(.+?한국경제TV\\)','',text).strip()\n",
        "      text = re.sub('\\(.+?조선비즈\\)','',text).strip()\n",
        "      text = re.sub('\\(.+?ZDNetKorea\\)','',text).strip()\n",
        "      text = re.sub('\\[.+?\\]','',text).strip()\n",
        "      text = re.sub('\\(사진.+?\\)','',text).strip()\n",
        "      # 신문사 이름 삭제 \n",
        "      text = re.sub('조선일보|뉴시스|아시아경제|이데일리|뉴스1|SBS|오마이뉴스|중앙일보|매일경제|문화일보|세계일보|머니투데이|서울경제|데일리안|KBS|MBN|YTN|프레시안|디지털타임스|국민일보(과거)|국민일보|헤럴드경제|한국일보|아이뉴스24|노컷뉴스|연합뉴스TV|서울일보|동아일보|한국경제|미디어오늘(과거)|미디어오늘|조세일보|파이낸셜뉴스|경향신문|채널A|머니S|TVCHOSUN|한겨례|전자신문|SBSCNBC|한국경제TV|조선비즈|ZDNetKorea','',text).strip()\n",
        "      # 000 기자, 000  가자, 000기자 삭제\n",
        "      text = re.sub('[ㄱ-힑]+ 기자|[ㄱ-힑]+  기자|[ㄱ-힑]+기자','',text).strip()    \n",
        "      text = re.sub('[a-zA-Z0-9]{1,20}\\@[a-zA-Z0-9]{1,20}\\.[a-z]{1,20}.+','',text).strip()    \n",
        "      # 특수기호 삭제\n",
        "      text = re.sub('[^a-zA-Z0-9ㄱ-힗.,”“\"% ]','',text).strip()\n",
        "      text = re.sub('[0-9]{1,4}.[0-9]{1,2}.[0-9]{1,2}.','',text).strip()\n",
        "      text = re.sub('무단 전재 및 재배포 금지','',text).strip()\n",
        "      text = re.sub(r'[\\n\\r\\t]', '', str(text))\n",
        "      text = re.sub('[^ ㄱ-ㅣ가-힣 0-9 A-Z a-z]+', '', str(text))\n",
        "      return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JJittnx6TG2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_hwang = pd.read_csv('/content/drive/My Drive/fininsight/21대 총선분석/TexkRank/Data/황교안_pre.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dE6sT65DR8h7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# df_hwang = pd.read_csv('/content/drive/My Drive/fininsight/21대 총선분석/TexkRank/Data/황교안_pre.csv')\n",
        "df_hwang['content_clean'] = df_hwang['content'].apply(pre_fx)\n",
        "df_hwang['content_ner'] = df_hwang['content_clean'].apply(main)\n",
        "df_hwang.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-DURceS6XyI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_hwang.to_csv('/content/drive/My Drive/fininsight/21대 총선분석/TexkRank/Data/황교안_ner.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lo5Lvlia5mRY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_lee = pd.read_csv('/content/drive/My Drive/fininsight/21대 총선분석/TexkRank/Data/이낙연_pre.csv')\n",
        "df_lee['content_clean'] = df_lee['content'].apply(pre_fx)\n",
        "df_lee['content_ner'] = df_lee['content'].apply(main)\n",
        "df_lee.to_csv('/content/drive/My Drive/fininsight/21대 총선분석/TexkRank/Data/이낙연_ner.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pM6_eel85mQM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_jongro = pd.read_csv('/content/drive/My Drive/fininsight/21대 총선분석/TexkRank/Data/종로구_pre.csv')\n",
        "df_jongro['content_clean'] = df_jongro['content'].apply(pre_fx)\n",
        "df_jongro['content_ner'] = df_jongro['content'].apply(main)\n",
        "df_jongro.to_csv('/content/drive/My Drive/fininsight/21대 총선분석/TexkRank/Data/종로구_ner.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0ATT35w5mNP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}