{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "source": [],
        "metadata": {
          "collapsed": false
        }
      }
    },
    "colab": {
      "name": "Interactive_shell_NER.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCepLlS7YBfC",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "# 환경설정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "leQR7nPHSLdt",
        "colab_type": "code",
        "outputId": "76c6239b-cbdc-4358-ec72-b7cd884b6fe6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XOvjO43SSSA",
        "colab_type": "code",
        "outputId": "528d0376-b78c-474e-f40c-a11efda829a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd /content/drive/My Drive/fininsight/Kobert_ner/pytorch-bert-crf-ner/"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/fininsight/Kobert_ner/pytorch-bert-crf-ner\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SdLHovhhSD5m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! pip install torch torchvision\n",
        "! pip install pytorch_pretrained_bert>=0.4.0\n",
        "! pip install mxnet>=1.5.0\n",
        "! pip install gluonnlp #>=0.6.0\n",
        "! pip install sentencepiece>=0.1.6\n",
        "! pip install git+https://github.com/kmkurn/pytorch-crf#egg=pytorch_crf\n",
        "! pip install transformers\n",
        "! pip install tb-nightly\n",
        "! pip install future"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SY-EZUKjSrdd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "outputId": "ede86af8-b338-4df7-adf1-215966c6b411"
      },
      "source": [
        "! pip install konlpy"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: konlpy in /usr/local/lib/python3.6/dist-packages (0.5.2)\n",
            "Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (0.7.2)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (4.2.6)\n",
            "Requirement already satisfied: beautifulsoup4==4.6.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (4.6.0)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.6/dist-packages (from konlpy) (1.18.1)\n",
            "Requirement already satisfied: tweepy>=3.7.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (3.8.0)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.6/dist-packages (from konlpy) (0.4.3)\n",
            "Requirement already satisfied: PySocks>=1.5.7 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.7.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.12.0)\n",
            "Requirement already satisfied: requests>=2.11.1 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (2.21.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.0)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy>=3.7.0->konlpy) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy>=3.7.0->konlpy) (2019.11.28)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QOQGI8S-vLqc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e83916d0-be7d-4238-baff-44d863130073"
      },
      "source": [
        "import torch\n",
        "torch.cuda.current_device()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-873301375205>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36mcurrent_device\u001b[0;34m()\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcurrent_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m     \u001b[0;34mr\"\"\"Returns the index of a currently selected device.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m     \u001b[0m_lazy_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_getDevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    195\u001b[0m                 \"Cannot re-initialize CUDA in forked subprocess. \" + msg)\n\u001b[1;32m    196\u001b[0m         \u001b[0m_check_driver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m         \u001b[0m_cudart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_cudart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0m_cudart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudaGetErrorName\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_char_p\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: cuda runtime error (100) : no CUDA-capable device is detected at /pytorch/aten/src/THC/THCGeneral.cpp:50"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJobUlyivOZM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.cuda.device(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d87IKjRXvOWj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.cuda.device_count()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PIXkx1QPvOT4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.cuda.get_device_name(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9WWtPuJvORQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.cuda.is_available()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-27T09:44:13.362955Z",
          "start_time": "2019-11-27T09:44:07.902764Z"
        },
        "id": "gphcT9snR8hi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 135
        },
        "outputId": "e870dfbe-97f5-42de-e159-f49d3c90cb6e"
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import json\n",
        "import pickle\n",
        "import torch\n",
        "from gluonnlp.data import SentencepieceTokenizer\n",
        "from model.net import KobertCRF\n",
        "from data_utils.utils import Config\n",
        "from data_utils.vocab_tokenizer import Tokenizer\n",
        "from data_utils.pad_sequence import keras_pad_fn\n",
        "from pathlib import Path"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/konlpy/tag/_okt.py:16: UserWarning: \"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.\n",
            "  warn('\"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.')\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-27T09:44:13.406972Z",
          "start_time": "2019-11-27T09:44:13.370406Z"
        },
        "id": "NsownfCpR8hs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DecoderFromNamedEntitySequence():\n",
        "    def __init__(self, tokenizer, index_to_ner):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.index_to_ner = index_to_ner\n",
        "\n",
        "    def __call__(self, list_of_input_ids, list_of_pred_ids):\n",
        "        input_token = self.tokenizer.decode_token_ids(list_of_input_ids)[0]\n",
        "        pred_ner_tag = [self.index_to_ner[pred_id] for pred_id in list_of_pred_ids[0]]\n",
        "\n",
        "        # ----------------------------- parsing list_of_ner_word ----------------------------- #\n",
        "        list_of_ner_word = []\n",
        "        entity_word, entity_tag, prev_entity_tag = \"\", \"\", \"\"\n",
        "        for i, pred_ner_tag_str in enumerate(pred_ner_tag):\n",
        "            if \"B-\" in pred_ner_tag_str:\n",
        "                entity_tag = pred_ner_tag_str[-3:]\n",
        "\n",
        "                if prev_entity_tag != entity_tag and prev_entity_tag != \"\":\n",
        "                    list_of_ner_word.append({\"word\": entity_word.replace(\"▁\", \" \"), \"tag\": prev_entity_tag, \"prob\": None})\n",
        "\n",
        "                entity_word = input_token[i]\n",
        "                prev_entity_tag = entity_tag\n",
        "            elif \"I-\"+entity_tag in pred_ner_tag_str:\n",
        "                entity_word += input_token[i]\n",
        "            else:\n",
        "                if entity_word != \"\" and entity_tag != \"\":\n",
        "                    list_of_ner_word.append({\"word\":entity_word.replace(\"▁\", \" \"), \"tag\":entity_tag, \"prob\":None})\n",
        "                entity_word, entity_tag, prev_entity_tag = \"\", \"\", \"\"\n",
        "\n",
        "\n",
        "        # ----------------------------- parsing decoding_ner_sentence ----------------------------- #\n",
        "        decoding_ner_sentence = \"\"\n",
        "        is_prev_entity = False\n",
        "        prev_entity_tag = \"\"\n",
        "        is_there_B_before_I = False\n",
        "\n",
        "        for i, (token_str, pred_ner_tag_str) in enumerate(zip(input_token, pred_ner_tag)):\n",
        "            if i == 0 or i == len(pred_ner_tag)-1: # remove [CLS], [SEP]\n",
        "                continue\n",
        "            token_str = token_str.replace('▁', ' ')  # '▁' 토큰을 띄어쓰기로 교체\n",
        "\n",
        "            if 'B-' in pred_ner_tag_str:\n",
        "                if is_prev_entity is True:\n",
        "                    decoding_ner_sentence += ':' + prev_entity_tag+ '>'\n",
        "\n",
        "                if token_str[0] == ' ':\n",
        "                    token_str = list(token_str)\n",
        "                    token_str[0] = ' <'\n",
        "                    token_str = ''.join(token_str)\n",
        "                    decoding_ner_sentence += token_str\n",
        "                else:\n",
        "                    decoding_ner_sentence += '<' + token_str\n",
        "                is_prev_entity = True\n",
        "                prev_entity_tag = pred_ner_tag_str[-3:] # 첫번째 예측을 기준으로 하겠음\n",
        "                is_there_B_before_I = True\n",
        "\n",
        "            elif 'I-' in pred_ner_tag_str:\n",
        "                decoding_ner_sentence += token_str\n",
        "\n",
        "                if is_there_B_before_I is True: # I가 나오기전에 B가 있어야하도록 체크\n",
        "                    is_prev_entity = True\n",
        "            else:\n",
        "                if is_prev_entity is True:\n",
        "                    decoding_ner_sentence += ':' + prev_entity_tag+ '>' + token_str\n",
        "                    is_prev_entity = False\n",
        "                    is_there_B_before_I = False\n",
        "                else:\n",
        "                    decoding_ner_sentence += token_str\n",
        "\n",
        "        return list_of_ner_word, decoding_ner_sentence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HC7qnWKUUjpV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! pip install pytorch-transformers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCVhT4WoUPxP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ! python train_bert_crf.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCdWF77q0ie2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "219a804f-776f-4f36-b065-be14a3d73423"
      },
      "source": [
        "! python -m pip install tqdm"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.28.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-27T09:44:13.441346Z",
          "start_time": "2019-11-27T09:44:13.414934Z"
        },
        "id": "SStkthkBR8hv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tqdm import tqdm\n",
        "from nltk.tokenize import sent_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "def main(x):\n",
        "    model_dir = Path('./experiments/base_model_with_crf')\n",
        "    # /content/drive/My Drive/fininsight/Kobert_ner/pytorch-bert-crf-ner/experiments\n",
        "    model_config = Config(json_path=model_dir / 'config.json') \n",
        "    \n",
        "\n",
        "    # load vocab & tokenizer \n",
        "    tok_path = \"./ptr_lm_model/tokenizer_78b3253a26.model\" \n",
        "    ptr_tokenizer = SentencepieceTokenizer(tok_path)\n",
        "\n",
        "    with open(model_dir / \"vocab.pkl\", 'rb') as f:\n",
        "        vocab = pickle.load(f)\n",
        "    tokenizer = Tokenizer(vocab=vocab, split_fn=ptr_tokenizer, pad_fn=keras_pad_fn, maxlen=model_config.maxlen)\n",
        "\n",
        "    # load ner_to_index.json\n",
        "    with open(model_dir / \"ner_to_index.json\", 'rb') as f:\n",
        "        ner_to_index = json.load(f)\n",
        "        index_to_ner = {v: k for k, v in ner_to_index.items()}\n",
        "\n",
        "    # model\n",
        "    model = KobertCRF(config=model_config, num_classes=len(ner_to_index), vocab=vocab)\n",
        "\n",
        "    # load\n",
        "    model_dict = model.state_dict()\n",
        "    \n",
        "    checkpoint = torch.load(\"/content/drive/My Drive/fininsight/Kobert_ner/pytorch-bert-crf-ner/experiments/base_model_with_crf_val/best-epoch-6-step-500-acc-0.957.bin\", map_location=torch.device('cpu'))\n",
        "    # checkpoint = torch.load(\"./experiments/base_model_with_crf/best-epoch-16-step-1500-acc-0.993.bin\", map_location=torch.device('cpu'))\n",
        "    # checkpoint = torch.load(\"./experiments/base_model_with_crf_val/best-epoch-12-step-1000-acc-0.960.bin\", map_location=torch.device('cpu'))\n",
        "    \n",
        "    convert_keys = {}\n",
        "    for k, v in checkpoint['model_state_dict'].items():\n",
        "        new_key_name = k.replace(\"module.\", '')\n",
        "        if new_key_name not in model_dict:\n",
        "            print(\"{} is not int model_dict\".format(new_key_name))\n",
        "            continue\n",
        "        convert_keys[new_key_name] = v\n",
        "\n",
        "    model.load_state_dict(convert_keys)\n",
        "    model.eval()\n",
        "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "    model.to(device)\n",
        "    decoder_from_res = DecoderFromNamedEntitySequence(tokenizer=tokenizer, index_to_ner=index_to_ner)\n",
        "\n",
        "\n",
        "    ner_text = []\n",
        "    for input_text in tqdm(sent_tokenize(x)):\n",
        "      try:\n",
        "        list_of_input_ids = tokenizer.list_of_string_to_list_of_cls_sep_token_ids([input_text])\n",
        "        x_input = torch.tensor(list_of_input_ids).long()\n",
        "        list_of_pred_ids = model(x_input)\n",
        "\n",
        "        list_of_ner_word, decoding_ner_sentence = decoder_from_res(list_of_input_ids=list_of_input_ids, list_of_pred_ids=list_of_pred_ids)\n",
        "        ner_text.append(decoding_ner_sentence)\n",
        "      \n",
        "      except:\n",
        "        pass\n",
        "        \n",
        "    return ner_text\n",
        "\n",
        "      # ner_texts.append(ner_text)\n",
        "\n",
        "    # return ner_texts"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21kVyI7AE1tl",
        "colab_type": "text"
      },
      "source": [
        "### 황교안"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwfPcq6-TvPn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Np16kCwOEJ9a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_hwang = pd.read_csv('/content/drive/My Drive/fininsight/21대 총선분석/TexkRank/Data/황교안_pre.csv')\n",
        "df_hwang.head(3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvtNN4jhm2KQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_hwang['kobert_ner'] = df_hwang['content'].apply(main)\n",
        "df_hwang.head(3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0S40f5dgEvjk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_hwang.to_csv('/content/drive/My Drive/fininsight/21대 총선분석/TexkRank/Data/황교안_ner.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMTqaZUIHWbd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGRLS1EKE3js",
        "colab_type": "text"
      },
      "source": [
        "### 이낙연"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oUNP-758e-SB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_lee = pd.read_csv('/content/drive/My Drive/fininsight/21대 총선분석/TexkRank/Data/이낙연_pre.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PtAXCZ0BfAzw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_lee['kobert_ner'] = df_lee['content'].apply(main)\n",
        "df_lee.head()\n",
        "df_lee.to_csv('/content/drive/My Drive/fininsight/21대 총선분석/TexkRank/Data/이낙연_ner.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6-kHkHQE46V",
        "colab_type": "text"
      },
      "source": [
        "### 종로구"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJis1ZmDXMhH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4BS1mQrfFi4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_jongro = pd.read_csv('/content/drive/My Drive/fininsight/21대 총선분석/TexkRank/Data/종로구_pre.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0ATT35w5mNP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_jongro['kobert_ner'] = df_jongro['content'].apply(main)\n",
        "df_jongro.to_csv('/content/drive/My Drive/fininsight/21대 총선분석/TexkRank/Data/종로구_ner.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_Bb087PHuUQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}