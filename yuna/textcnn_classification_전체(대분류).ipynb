{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "textcnn_classification_전체(대분류).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vs10c0mRTpgb",
        "colab_type": "text"
      },
      "source": [
        "# 환경설정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVZQAktbTh2W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/kakao/khaiii.git\n",
        "!pip install cmake\n",
        "!mkdir build\n",
        "!cd build && cmake /content/khaiii\n",
        "!cd /content/build/ && make all\n",
        "!cd /content/build/ && make resource\n",
        "!cd /content/build && make install\n",
        "!cd /content/build && make package_python\n",
        "!pip install /content/build/package_python"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRZ63yoWTyVq",
        "colab_type": "code",
        "outputId": "f8f8d558-2ff9-4c12-ffbc-b2b33182cdb5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRQfFYfzTyS4",
        "colab_type": "code",
        "outputId": "1ec5de7b-f7d0-4c52-f0c3-0dee224741fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "cd /content/drive/My Drive/fininsight/21대 총선분석/Text Classification/TextCNN/cnn-text-classification-tf"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/fininsight/21대 총선분석/Text Classification/TextCNN/cnn-text-classification-tf\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FjFqEDauT1wR",
        "colab_type": "text"
      },
      "source": [
        "# 데이터 생성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fRMLup3pHeZ",
        "colab_type": "code",
        "outputId": "37ad4422-92f8-44cf-e2ad-335be1c083eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 611
        }
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('전체.csv')\n",
        "df.head(3)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>url</th>\n",
              "      <th>category1</th>\n",
              "      <th>category2</th>\n",
              "      <th>date</th>\n",
              "      <th>title</th>\n",
              "      <th>media</th>\n",
              "      <th>inputdate</th>\n",
              "      <th>summary</th>\n",
              "      <th>content</th>\n",
              "      <th>oricategory</th>\n",
              "      <th>updatedate</th>\n",
              "      <th>like</th>\n",
              "      <th>angry</th>\n",
              "      <th>comment</th>\n",
              "      <th>warm</th>\n",
              "      <th>want</th>\n",
              "      <th>sad</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>https://news.naver.com/main/read.nhn?mode=LS2D...</td>\n",
              "      <td>정치</td>\n",
              "      <td>국방/외교</td>\n",
              "      <td>2019-03-05</td>\n",
              "      <td>정세현 북미회담, 의도된 결렬…볼턴 '재수없는 사람'(종합)</td>\n",
              "      <td>뉴시스</td>\n",
              "      <td>2019.03.05. 오후 3:00</td>\n",
              "      <td>\"북미 간 실무협상에서 합의 거의 이뤄졌을 것\"</td>\n",
              "      <td>// flash 오류를 우회하기 위한 함수 추가\\nfunction _flas...</td>\n",
              "      <td>정치</td>\n",
              "      <td>2020-03-20 02:18:21</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>https://news.naver.com/main/read.nhn?mode=LS2D...</td>\n",
              "      <td>정치</td>\n",
              "      <td>국방/외교</td>\n",
              "      <td>2019-08-12</td>\n",
              "      <td>정부 일본 백색국가 제외</td>\n",
              "      <td>연합뉴스</td>\n",
              "      <td>2019.08.12. 오후 2:15</td>\n",
              "      <td>NaN</td>\n",
              "      <td>// flash 오류를 우회하기 위한 함수 추가\\nfunction _flas...</td>\n",
              "      <td>경제</td>\n",
              "      <td>2020-03-19 12:54:58</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>https://news.naver.com/main/read.nhn?mode=LS2D...</td>\n",
              "      <td>정치</td>\n",
              "      <td>국방/외교</td>\n",
              "      <td>2019-02-13</td>\n",
              "      <td>낸시 펠로시 만난 문희상 의장과 조윤제 주미대사</td>\n",
              "      <td>연합뉴스</td>\n",
              "      <td>2019.02.13. 오후 1:19</td>\n",
              "      <td>NaN</td>\n",
              "      <td>// flash 오류를 우회하기 위한 함수 추가\\nfunction _flas...</td>\n",
              "      <td>정치</td>\n",
              "      <td>2020-03-19 12:27:21</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 url category1  ... want sad\n",
              "0  https://news.naver.com/main/read.nhn?mode=LS2D...        정치  ...  NaN NaN\n",
              "1  https://news.naver.com/main/read.nhn?mode=LS2D...        정치  ...  NaN NaN\n",
              "2  https://news.naver.com/main/read.nhn?mode=LS2D...        정치  ...  NaN NaN\n",
              "\n",
              "[3 rows x 17 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95SapzJBpBke",
        "colab_type": "code",
        "outputId": "4e17edce-20bd-4278-aa97-b29e7c889791",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(df.shape)\n",
        "df =df.dropna(subset=['content']) \n",
        "print(df.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(410392, 17)\n",
            "(410374, 17)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CpR_rrjnpJei",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "def pre_fx(text):\n",
        "    # 이메일 등장하면, 그 뒷문장 모두 삭제 \n",
        "    text = re.sub(\"[a-zA-Z0-9]+\\@[a-zA-Z0-9]+\\.[a-z]{1,3}.[a-z]{1,3}.+\",'',text).strip()\n",
        "    text = re.sub('\\(.+?연합뉴스\\)','',text).strip() # (서울=연합뉴스)\n",
        "    text = re.sub('\\(.+?연합인포맥스\\)','',text).strip()\n",
        "    text = re.sub('\\(.+?이데일리\\)','',text).strip()\n",
        "    text = re.sub('\\(.+?조선일보\\)','',text).strip()\n",
        "    text = re.sub('\\(.+?뉴시스\\)',' ',text).strip()\n",
        "    text = re.sub('\\(.+?뉴스1\\)','',text).strip()\n",
        "    text = re.sub('\\(.+?SBS\\)','',text).strip()\n",
        "    text = re.sub('\\(.+?오마이뉴스\\)','',text).strip()\n",
        "    text = re.sub('\\(.+?중앙일보\\)','',text).strip()\n",
        "    text = re.sub('\\(.+?매일경제\\)','',text).strip()\n",
        "    text = re.sub('\\(.+?문화일보\\)','',text).strip()\n",
        "    text = re.sub('\\(.+?세계일보\\)','',text).strip()\n",
        "    text = re.sub('\\(.+?머니투데이\\)','',text).strip()\n",
        "    text = re.sub('\\(.+?서울경제\\)','',text).strip()\n",
        "    text = re.sub('\\(.+?데일리안\\)','',text).strip()\n",
        "    text = re.sub('\\(.+?KBS\\)','',text).strip()\n",
        "    text = re.sub('\\(.+?MBN\\)','',text).strip()\n",
        "    text = re.sub('\\(.+?YTN\\)','',text).strip()\n",
        "    text = re.sub('\\(.+?프레시안\\)','',text).strip()\n",
        "    text = re.sub('\\(.+?디지털타임즈\\)','',text).strip()\n",
        "    text = re.sub('\\(.+?국민일보(과거)\\)','',text).strip()\n",
        "    text = re.sub('\\(.+?국민일보\\)','',text).strip()\n",
        "    text = re.sub('\\(.+?헤드럴경제\\)','',text).strip()\n",
        "    text = re.sub('\\(.+?한국일보\\)','',text).strip()\n",
        "    text = re.sub('\\(.+?아이뉴스24\\)','',text).strip()\n",
        "    text = re.sub('\\(.+?노컷뉴스\\)','',text).strip()\n",
        "    text = re.sub('\\(.+?연합뉴스TV\\)','',text).strip()\n",
        "    text = re.sub('\\(.+?서울일보\\)','',text).strip()\n",
        "    text = re.sub('\\(.+?동아일보\\)','',text).strip()\n",
        "    text = re.sub('\\(.+?한국경제\\)','',text).strip()\n",
        "    text = re.sub('\\(.+?미디어오늘(과거)\\)','',text).strip()\n",
        "    text = re.sub('\\(.+?미디어오늘\\)','',text).strip()\n",
        "    text = re.sub('\\(.+?조세일보\\)','',text).strip()\n",
        "    text = re.sub('\\(.+?파이낸셜뉴스\\)','',text).strip()\n",
        "    text = re.sub('\\(.+?경향신문\\)','',text).strip()\n",
        "    text = re.sub('\\(.+?채널A\\)','',text).strip()\n",
        "    text = re.sub('\\(.+?머니S\\)','',text).strip()\n",
        "    text = re.sub('\\(.+?TVCHOSUN\\)','',text).strip()\n",
        "    text = re.sub('\\(.+?한겨례\\)','',text).strip()\n",
        "    text = re.sub('\\(.+?전자신문\\)','',text).strip()\n",
        "    text = re.sub('\\(.+?SBSCNBC\\)','',text).strip()\n",
        "    text = re.sub('\\(.+?한국경제TV\\)','',text).strip()\n",
        "    text = re.sub('\\(.+?조선비즈\\)','',text).strip()\n",
        "    text = re.sub('\\(.+?ZDNetKorea\\)','',text).strip()\n",
        "    text = re.sub('\\[.+?\\]','',text).strip()\n",
        "    text = re.sub('\\(사진.+?\\)','',text).strip()\n",
        "    # 신문사 이름 삭제 \n",
        "    text = re.sub('조선일보|뉴시스|아시아경제|이데일리|뉴스1|SBS|오마이뉴스|중앙일보|매일경제|문화일보|세계일보|머니투데이|서울경제|데일리안|KBS|MBN|YTN|프레시안|디지털타임스|국민일보(과거)|국민일보|헤럴드경제|한국일보|아이뉴스24|노컷뉴스|연합뉴스TV|서울일보|동아일보|한국경제|미디어오늘(과거)|미디어오늘|조세일보|파이낸셜뉴스|경향신문|채널A|머니S|TVCHOSUN|한겨례|전자신문|SBSCNBC|한국경제TV|조선비즈|ZDNetKorea','',text).strip()\n",
        "    # 000 기자, 000  가자, 000기자 삭제\n",
        "    text = re.sub('[ㄱ-힑]+ 기자|[ㄱ-힑]+  기자|[ㄱ-힑]+기자','',text).strip()    \n",
        "    text = re.sub('[a-zA-Z0-9]{1,20}\\@[a-zA-Z0-9]{1,20}\\.[a-z]{1,20}.+','',text).strip()    \n",
        "\n",
        "    return text\n",
        "\n",
        "df['content'] = df['content'].map(lambda x : pre_fx(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8v1HMXRepJaJ",
        "colab_type": "code",
        "outputId": "b0e5821d-f147-459e-cfd8-4e442ab6ea9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 715
        }
      },
      "source": [
        "#기존 클렌징으로 부족한 부분\n",
        "import re\n",
        "def filter(s):\n",
        "  hangul = re.compile('[^ ㄱ-ㅣ가-힣]+') # 한글과 띄어쓰기를 제외한 모든 글자\n",
        "  result = hangul.sub('', s) # 한글과 띄어쓰기를 제외한 모든 부분을 제거\n",
        "  return result\n",
        "\n",
        "df['content'] = df['content'].apply(filter)\n",
        "df.head(3)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>url</th>\n",
              "      <th>category1</th>\n",
              "      <th>category2</th>\n",
              "      <th>date</th>\n",
              "      <th>title</th>\n",
              "      <th>media</th>\n",
              "      <th>inputdate</th>\n",
              "      <th>summary</th>\n",
              "      <th>content</th>\n",
              "      <th>oricategory</th>\n",
              "      <th>updatedate</th>\n",
              "      <th>like</th>\n",
              "      <th>angry</th>\n",
              "      <th>comment</th>\n",
              "      <th>warm</th>\n",
              "      <th>want</th>\n",
              "      <th>sad</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>https://news.naver.com/main/read.nhn?mode=LS2D...</td>\n",
              "      <td>정치</td>\n",
              "      <td>국방/외교</td>\n",
              "      <td>2019-03-05</td>\n",
              "      <td>정세현 북미회담, 의도된 결렬…볼턴 '재수없는 사람'(종합)</td>\n",
              "      <td>뉴시스</td>\n",
              "      <td>2019.03.05. 오후 3:00</td>\n",
              "      <td>\"북미 간 실무협상에서 합의 거의 이뤄졌을 것\"</td>\n",
              "      <td>오류를 우회하기 위한 함수 추가    북미 간 실무협상에서 합의 거의 이뤄졌을 ...</td>\n",
              "      <td>정치</td>\n",
              "      <td>2020-03-20 02:18:21</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>https://news.naver.com/main/read.nhn?mode=LS2D...</td>\n",
              "      <td>정치</td>\n",
              "      <td>국방/외교</td>\n",
              "      <td>2019-08-12</td>\n",
              "      <td>정부 일본 백색국가 제외</td>\n",
              "      <td>연합뉴스</td>\n",
              "      <td>2019.08.12. 오후 2:15</td>\n",
              "      <td>NaN</td>\n",
              "      <td>오류를 우회하기 위한 함수 추가    성윤모 산업통상자원부 장관이 일 세종시 정...</td>\n",
              "      <td>경제</td>\n",
              "      <td>2020-03-19 12:54:58</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>https://news.naver.com/main/read.nhn?mode=LS2D...</td>\n",
              "      <td>정치</td>\n",
              "      <td>국방/외교</td>\n",
              "      <td>2019-02-13</td>\n",
              "      <td>낸시 펠로시 만난 문희상 의장과 조윤제 주미대사</td>\n",
              "      <td>연합뉴스</td>\n",
              "      <td>2019.02.13. 오후 1:19</td>\n",
              "      <td>NaN</td>\n",
              "      <td>오류를 우회하기 위한 함수 추가    미국을 방문 중인 문희상 국회의장오른쪽이 ...</td>\n",
              "      <td>정치</td>\n",
              "      <td>2020-03-19 12:27:21</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 url category1  ... want sad\n",
              "0  https://news.naver.com/main/read.nhn?mode=LS2D...        정치  ...  NaN NaN\n",
              "1  https://news.naver.com/main/read.nhn?mode=LS2D...        정치  ...  NaN NaN\n",
              "2  https://news.naver.com/main/read.nhn?mode=LS2D...        정치  ...  NaN NaN\n",
              "\n",
              "[3 rows x 17 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPEVKO3cpIq0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # 토큰화\n",
        "# from khaiii import KhaiiiApi\n",
        "# api = KhaiiiApi()\n",
        "\n",
        "# def khaiii_token(sentence):\n",
        "#   token_list = []\n",
        "#   try:\n",
        "#     for word in api.analyze(str(sentence)):\n",
        "#       morphs_str = ' '.join([m.lex for m in word.morphs if m.tag in ['NNG', 'NNP', 'NNB', 'NR', 'NP', 'VA']])\n",
        "#       token_list.append(morphs_str)\n",
        "  \n",
        "#   except:\n",
        "#     pass\n",
        "\n",
        "#   return token_list  \n",
        "\n",
        "# df['khaiii_token'] = df['content'].apply(khaiii_token)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wvxI0UNBl5kH",
        "colab_type": "text"
      },
      "source": [
        "## mecab 토큰화"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eoy7Sx-4l5QO",
        "colab_type": "code",
        "outputId": "0a85ec74-b102-4bde-ba4b-faa49f797981",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "! git clone https://github.com/SOMJANG/Mecab-ko-for-Google-Colab.git"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'Mecab-ko-for-Google-Colab' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8G7H9aTl3WS",
        "colab_type": "code",
        "outputId": "0ee1b7c7-39be-43e5-f39f-70972eb9f0c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        " cd Mecab-ko-for-Google-Colab"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/fininsight/21대 총선분석/Text Classification/TextCNN/cnn-text-classification-tf/Mecab-ko-for-Google-Colab\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xz869lQl3Rn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! bash install_mecab-ko_on_colab190912.sh"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vjW_1wxl3LI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from konlpy.tag import Mecab \n",
        "mecab = Mecab() \n",
        "\n",
        "def mecab_morphs(sentence):\n",
        "  morphs = mecab.morphs(sentence) \n",
        "  return morphs\n",
        "\n",
        "df['mecan_token'] = df['content'].apply(mecab_morphs)\n",
        "df.head(3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CbA4fiaEpYPW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def joini(x):\n",
        "  y = []\n",
        "  for xx in x:\n",
        "    if xx != '':\n",
        "      y.append(xx)\n",
        "\n",
        "  return ' '.join(y)\n",
        "\n",
        "df['tokens'] = df['mecan_token'].apply(joini)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bQnamQYpYLd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df =df.dropna(subset=['tokens']) \n",
        "df['data'] = df['tokens'] +',' + df['category1']\n",
        "df.head(3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFTIaI9kIwqr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train, dev = train_test_split(df, test_size=0.33, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_YRNi8Ox92D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = list(df['category1'].unique())\n",
        "x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cRhumCeyNye",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cd /content/drive/My Drive/fininsight/21대 총선분석/Text Classification/TextCNN/cnn-text-classification-tf/data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgU9gzugyR4o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f = open(\"cls.txt\" , 'w')\n",
        "for i in range(len(list(df['category1'].unique()))):\n",
        "  try:\n",
        "    f.write(list(df['category1'].unique())[i])\n",
        "    f.write('\\n')\n",
        "  except:\n",
        "    pass\n",
        "f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jyMYuKAfpIoU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f = open(\"train.txt\" , 'w')\n",
        "for i in range(len(train['data'])):\n",
        "  try:\n",
        "    f.write(train['data'][i])\n",
        "    f.write('\\n')\n",
        "  except:\n",
        "    pass\n",
        "f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayjbmU6opthc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f = open(\"dev.txt\" , 'w')\n",
        "for i in range(len(dev['data'])):\n",
        "  try:\n",
        "    f.write(dev['data'][i])\n",
        "    f.write('\\n')\n",
        "  except:\n",
        "    pass\n",
        "f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DquFWLE7UNnO",
        "colab_type": "text"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TUl2wHcUyu2k",
        "colab_type": "code",
        "outputId": "a6ea3a76-ea0d-45d4-e566-951f74519389",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "cd /content/drive/My Drive/fininsight/21대 총선분석/Text Classification/TextCNN/cnn-text-classification-tf"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/fininsight/21대 총선분석/Text Classification/TextCNN/cnn-text-classification-tf\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmvreqMHUMVG",
        "colab_type": "code",
        "outputId": "2f980ea2-dcd2-4d10-fd97-0539e762adc7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 864
        }
      },
      "source": [
        "! python train.py"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Parameters:\n",
            "ALLOW_SOFT_PLACEMENT=<absl.flags._flag.BooleanFlag object at 0x7f2c06601780>\n",
            "ALSOLOGTOSTDERR=<absl.flags._flag.BooleanFlag object at 0x7f2c2d296208>\n",
            "BATCH_SIZE=<absl.flags._flag.Flag object at 0x7f2c065eac18>\n",
            "CHECKPOINT_EVERY=<absl.flags._flag.Flag object at 0x7f2c06601748>\n",
            "CLASS_DATA_FILE=<absl.flags._flag.Flag object at 0x7f2c065bc198>\n",
            "DEV_DATA_FILE=<absl.flags._flag.Flag object at 0x7f2c065bc128>\n",
            "DROPOUT_KEEP_PROB=<absl.flags._flag.Flag object at 0x7f2c065eaa58>\n",
            "EMBEDDING_DIM=<absl.flags._flag.Flag object at 0x7f2c6771c128>\n",
            "EVALUATE_EVERY=<absl.flags._flag.Flag object at 0x7f2c065f6c50>\n",
            "FILTER_SIZES=<absl.flags._flag.Flag object at 0x7f2c18ca7cc0>\n",
            "L2_REG_LAMBDA=<absl.flags._flag.Flag object at 0x7f2c065eab70>\n",
            "LOG_DEVICE_PLACEMENT=<absl.flags._flag.BooleanFlag object at 0x7f2c065b5f60>\n",
            "LOG_DIR=<absl.flags._flag.Flag object at 0x7f2c2d2962b0>\n",
            "LOGTOSTDERR=<absl.flags._flag.BooleanFlag object at 0x7f2c2d286e48>\n",
            "NUM_EPOCHS=<absl.flags._flag.Flag object at 0x7f2c065f61d0>\n",
            "NUM_FILTERS=<absl.flags._flag.Flag object at 0x7f2c18cbf898>\n",
            "ONLY_CHECK_ARGS=<absl.flags._flag.BooleanFlag object at 0x7f2c2d296a90>\n",
            "OP_CONVERSION_FALLBACK_TO_WHILE_LOOP=<absl.flags._flag.BooleanFlag object at 0x7f2c2ad4e780>\n",
            "PDB_POST_MORTEM=<absl.flags._flag.BooleanFlag object at 0x7f2c2d7b7358>\n",
            "PROFILE_FILE=<absl.flags._flag.Flag object at 0x7f2c2d2969e8>\n",
            "RUN_WITH_PDB=<absl.flags._flag.BooleanFlag object at 0x7f2c2d7b7160>\n",
            "RUN_WITH_PROFILING=<absl.flags._flag.BooleanFlag object at 0x7f2c2d296940>\n",
            "SHOWPREFIXFORINFO=<absl.flags._flag.BooleanFlag object at 0x7f2c2d296518>\n",
            "STDERRTHRESHOLD=<absl.logging._StderrthresholdFlag object at 0x7f2c2d296400>\n",
            "TEST_RANDOM_SEED=<absl.flags._flag.Flag object at 0x7f2c21deaf60>\n",
            "TEST_RANDOMIZE_ORDERING_SEED=<absl.flags._flag.Flag object at 0x7f2c21d7a080>\n",
            "TEST_SRCDIR=<absl.flags._flag.Flag object at 0x7f2c21df30f0>\n",
            "TEST_TMPDIR=<absl.flags._flag.Flag object at 0x7f2c21df32e8>\n",
            "TRAIN_DATA_FILE=<absl.flags._flag.Flag object at 0x7f2c065bc0b8>\n",
            "USE_CPROFILE_FOR_PROFILING=<absl.flags._flag.BooleanFlag object at 0x7f2c2d296a20>\n",
            "V=<absl.logging._VerbosityFlag object at 0x7f2c2d296320>\n",
            "VERBOSITY=<absl.logging._VerbosityFlag object at 0x7f2c2d296320>\n",
            "XML_OUTPUT_FILE=<absl.flags._flag.Flag object at 0x7f2c21d7aa20>\n",
            "\n",
            "Loading data...\n",
            "WARNING:tensorflow:From /content/drive/My Drive/fininsight/21대 총선분석/Text Classification/TextCNN/cnn-text-classification-tf/word_data_processor.py:13: VocabularyProcessor.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tensorflow/transform or tf.data.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/contrib/learn/python/learn/preprocessing/text.py:154: CategoricalVocabulary.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.categorical_vocabulary) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tensorflow/transform or tf.data.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/contrib/learn/python/learn/preprocessing/text.py:170: tokenizer (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tensorflow/transform or tf.data.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ool-2qzjUMS0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! python eval.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Zo8u4U2UMRY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "pd.read_csv('prediction.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rZHJbksUMOT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}